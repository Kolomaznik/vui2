{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kolomaznik/vui2/blob/main/2022/Chatbots/readme.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ChatBots "
      ],
      "metadata": {
        "id": "QMxEZLyy14HZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prečo chatboti**\n",
        "\n",
        "Chatboty umožňujú podnikom **spojiť sa so zákazníkmi osobnejším spôsobom** bez nákladov na ľudských zástupcov.\n",
        "\n",
        "Odovzdáva **problémy zákazníka živej osobe**, ak sa problém stane príliš zložitým na to, aby ho chatbot vyriešil.\n",
        "Šetrí času a peňazí\n",
        "\n",
        "Chatboty dokážu **automatizovať úlohy**, ktoré sú vykonávané často a v konkrétnych časoch. To dáva zamestnancom čas sústrediť sa na dôležitejšie úlohy a zákazník nemusí čakať na odpoveď.\n",
        "\n",
        "V minulosti sa organizácie spoliehali na pasívnu interakciu so zákazníkmi a čakali, kým ich zákazníci oslovia ako prví. \n",
        "S chatbotmi môžu organizácie proaktívne interagovať, pretože roboty môžu iniciovať konverzácie a **monitorovať**, ako zákazníci používajú webové stránky. Organizácie potom môžu **použiť informácie** zhromaždené z monitorovania, aby ponúkli konkrétne stimuly pre kupujúcich, pomohli používateľom pri navigácii na stránke a odpovedali na budúce otázky.\n",
        "\n",
        "Roboty môžu tiež zaznamenávať používateľské údaje na **sledovanie správania** a nákupných vzorcov, ako lepšie predávať svoje produkty a služby,\n",
        "\n",
        "Chatboty dokážu vyriešiť obavy a otázky zákazníkov vo viacerých jazykoch. \n",
        "\n",
        "Ich **24/7** prístup umožňuje zákazníkom ich používať bez ohľadu na čas alebo časové pásmo.\n",
        "\n",
        "**Vývoj**\n",
        "\n",
        "*ELIZA*\n",
        "* 1964, MIT\n",
        "* SLIP\n",
        "* Pokus o Turingov test\n",
        "* Využitý pattern matching a substitučná metodológia\n",
        "* Ilúzia porozumenia zo strany programu\n",
        "* Chýba kontext rozhovoru\n",
        "\n",
        "Pomocou „porovnávania vzorov“ a substitučnej metodológie poskytuje program vopred pripravené odpovede, vďaka ktorým majú používatelia pocit, že sa rozprávajú s niekým, kto pochopil ich vstup.\n",
        "Program bol obmedzený skriptami, ktoré boli uložené v programe\n",
        "\n",
        "\n",
        "*PARRY*\n",
        "* 1972\n",
        "* Známy rozhovor medzi terapeutom a paranoidním schizofrenikom (PARRY)\n",
        "* Prešiel Turingovým testom\n",
        "\n",
        "V roku 1971 Kenneth Colby, psychiater Stanfordského laboratória umelej inteligencie, uvažoval, či by počítače mohli prispieť k pochopeniu funkcie mozgu. \n",
        "Veril, že počítač môže pomôcť pri liečbe pacientov s duševnými chorobami. \n",
        "Tieto myšlienky viedli Colbyho k vyvinutiu Parryho, počítačového programu, ktorý simuloval človeka so schizofréniou. \n",
        "Colby veril, že Parry môže pomôcť vzdelávať študentov medicíny skôr, ako začnú liečiť pacientov. \n",
        "Parry bol považovaný za prvého chatovacieho robota, ktorý prešiel Turingovým testom. \n",
        "Už vtedy jej vznik rozpútal vážnu debatu o možnostiach umelej inteligencie.\n",
        "\n",
        "*Ďalší chatboti**\n",
        "\n",
        "* KL-ONE (1974) – reprezentácia znalostí v sémantických sieťach a rámcoch\n",
        "* Jabberwacky (1982) – Simulácia ľudskej konverzácie zábavnou formou\n",
        "  contextual pattern matching\n",
        "* Dr. Sbaitso (1992) – Rozhovor so psychológom. „Why do you feel that way?“\n",
        "* A.L.I.C.E. (1995) – Online konverzácia ako s reálnym človekom\n",
        "  * heuristic pattern matching \n",
        "* SmarterChild (2001) – MSN Messenger, predchodca Siri\n",
        "* Siri (2010)\n",
        "* Google Now (2012)\n",
        "* Cortana (2014)\n",
        "* Alexa (2014)\n",
        "* …\n",
        "\n",
        "**Turing test**\n",
        "\n",
        "V roku 1950 Alan Turing, počítačový priekopník, napísal vedeckú prácu s názvom „Výpočtové stroje a inteligencia“. V dokumente vedec naznačil, že počítačový program môže myslieť a hovoriť ako človek. Turing navrhol experiment s názvom Imitation Game, ktorý je známy ako Turingov test, aby to dokázal. V Turingovom experimente osoba označená ako sudca četovala cez počítač s človekom a strojom, ktorých nebolo vidieť, má za úlohu rozoznať či si píše so strojom alebo človekom\n",
        "\n",
        "\n",
        "**Typy chatbotov**\n",
        "\n",
        "* rule-based\n",
        "\n",
        "  * Dajú sa hravo prirovnať k filmovým hercom, pretože sa rovnako ako oni vždy držia scenára. \n",
        "  * Roboty založené na pravidlách poskytujú odpovede na základe súboru pravidiel if/then, ktoré sa môžu líšiť v zložitosti. Tieto pravidlá definuje a implementuje návrhár chatbotov.\n",
        "  * V tomto bode je vhodné dodať, že chatboty založené na pravidlách nerozumejú kontextu konverzácie. Poskytujú zodpovedajúce odpovede len vtedy, keď používatelia použijú kľúčové slovo alebo príkaz, na ktorý boli naprogramovaní.\n",
        "\n",
        "  * Keď sa robotovi založenému na pravidlách položí otázka ako: „Ako môžem obnoviť svoje heslo? najprv hľadá známe kľúčové slová vo vete. V tomto príklade sú kľúčové slová „resetovať“ a „heslo“. Potom tieto kľúčové slová porovná s odpoveďami dostupnými v databáze, aby poskytla odpoveď.\n",
        "\n",
        "  * Stojí za to zdôrazniť, že konverzačné rozhrania založené na pravidlách sa nedokážu poučiť z minulých skúseností\n",
        "\n",
        "  * Roboty založené na pravidlách sú najlacnejšie na zostavenie a najjednoduchšie sa trénujú.\n",
        "\n",
        "  * Vysoko špecifický a štrukturovaný\n",
        "  * Problémom môže byť zaciklená konverzácia\n",
        "* Pattern matching alg.\n",
        "  * Hrubá sila – vývojár musí definovať každý vzor a odpovedať naň\n",
        "  * Preddefinovaný slovník – hľadá kľúčové slová\n",
        "  * ELIZA\n",
        "  * Najčastejšie používaná metóda\n",
        "  * Príklad:\n",
        "    * Input: “I’m very happy“\n",
        "    * Rule: “I’m” -> “You are”\n",
        "    * Response generation algorithm: “I am delighted to hear”\n",
        "    * Output: “I am delighted to hear you are happy”\n",
        "\n",
        "* AIML\n",
        "  * AIML je skratka pre Artificial Intelligence Markup Language. AIML sa používa na vytvorenie alebo prispôsobenie Alicebota, čo je aplikácia chat-bot založená na A.L.I.C.E. (Artificial Linguistic Internet Computer Entity) slobodný softvér.\n",
        "\n",
        "  * AIML obsahuje kolekciu pravidiel, ktoré definujú konverzačné schopnosti chatbota.\n",
        "  * Čím viac pravidiel pridáme do AIML – tým inteligentnejší je chatbot.\n",
        "  * Jedna aplikácia chatbota môže mať viacero sád AIML a môže sa správať odlišne.\n",
        "  * Ako obmedzenie chatbota založeného na AIML, ak nie je splnený žiadny vstupný vzor, ​​bot jednoducho odpovie štandardným vyhlásením „nerozumel fráze“.\n",
        "\n",
        "  * \\<aiml> - rámcuje dokument\n",
        "  * \\<category> - označuje kategóriu \n",
        "  * \\<pattern>  - vstup\n",
        "  * \\<template> - výstup\n",
        "  * \\<random> - náhodný výstup\n",
        "  * \\<set> - uloženie do premennej \n",
        "  * \\<get> - zavolanie premennej \n",
        "  * \\<star> - wildcard\n",
        "\n",
        "* AI chatbots\n",
        "\n",
        "  * AI chatbot je softvér, ktorý môže voľne komunikovať s používateľmi. Komunikačné aplikácie AI sú oveľa lepšími hovorcami ako ich náprotivky založené na pravidlách, pretože využívajú strojové učenie, spracovanie prirodzeného jazyka (NLP) a analýzu sentimentu.\n",
        "\n",
        "  * Strojové učenie (ML) umožňuje robotom identifikovať vzory v používateľských vstupoch, robiť rozhodnutia a učiť sa z minulých konverzácií\n",
        "\n",
        "  * Spracovanie prirodzeného jazyka (NLP) pomáha robotom pochopiť, ako ľudia komunikujú, a umožňuje im toto správanie replikovať. NLP im umožňuje pochopiť kontext konverzácie, aj keď niekto urobí pravopisnú chybu alebo použije žargón.\n",
        "    * NLU alebo Natural Language Understanding je vetva NLP. Ide o strojové čítanie s porozumením a uistenie sa, že stroj rozumie skutočnému významu textu. Vedeckejšie povedané, NLU sa odohráva, keď stroj konvertuje zadané údaje používateľa (to, čo hovorí) do logickej formy, ktorej algoritmy počítača rozumejú. A čím presnejší a spoľahlivejší je nástroj AI pri identifikácii zámeru používateľa, tým výkonnejšie bude riešenie, ktoré poháňa.\n",
        "\n",
        "    * NLG, alebo Natural Language Generation, je ďalšou podmnožinou NLP, ktorá je v podstate NLU naopak: stroj generuje logickú odpoveď, ktorú potom prevádza na odpoveď prirodzeného jazyka, ktorej ľudský čitateľ ľahko porozumie.\n",
        "\n",
        "  * Analýza sentimentu pomáha chatbotom pochopiť emócie používateľov.\n",
        "\n",
        " * Komunikačné roboty AI musia byť dobre vycvičené a vybavené preddefinovanými odpoveďami, aby mohli začať. Ako sa však učia z minulých rozhovorov, nie je potrebné ich neskôr manuálne aktualizovať.\n",
        "\n",
        "  * Príklad \n",
        "    * Roboty AI sú s každou konverzáciou inteligentnejšie, čo znamená, že jednoducho odzrkadľujú správanie používateľov.\n",
        "experimente spoločnosti Microsoft s názvom „Conversational Understanding“.\n",
        "Experiment zahŕňal spustenie Tay, robota AI, na Twitteri. Tay mala chatovať s mileniálmi a dokázať, že počítačový program môže byť múdrejší pomocou „neformálnych a hravých rozhovorov“.\n",
        "Experiment ukázal, že predpoklady Microsoftu boli správne; výsledky experimentu však neboli ani zďaleka očakávané. Po pár hodinách chatovania s používateľmi Twitteru Tay začala posielať rasistické a urážlivé tweety vrátane správ ako „Hitler mal pravdu“ alebo „11. september bol internou úlohou“.\n",
        "\n",
        "**Kroky**\n",
        "\n",
        "1. Tokenizácia: Chatbot začína rozsekaním textu na kúsky (nazývané aj „tokeny“) a odstránením interpunkcie\n",
        "\n",
        "2. Normalizácia: Robot následne odstráni detaily, ktoré nie sú relevantné, a prevedie slová na ich „normálnu“ verziu, napríklad tak, že všetko zmení na malé písmená\n",
        "\n",
        "3. Rozoznávanie entít: Teraz, keď sú všetky slová normalizované, chatbot sa snaží identifikovať, na ktorý typ veci sa odkazuje. Napríklad by to identifikovalo Severnú Ameriku ako miesto, 67 % ako percento a Google ako organizáciu.\n",
        "\n",
        "4. Analýza závislosti: V ďalšom kroku robot identifikuje úlohu, ktorú každé slovo hrá vo vete, ako je podstatné meno, sloveso, prídavné meno alebo objekt.\n",
        "\n",
        "5. Generovanie: Nakoniec chatbot vygeneruje množstvo odpovedí pomocou informácií určených vo všetkých ostatných krokoch a vyberie najvhodnejšiu odpoveď, ktorú pošle používateľovi\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Y7O-M-W6LLOt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The ChatterBot library combines language corpora, text processing, machine learning algorithms, and data storage and retrieval to allow you to build flexible chatbots.\n",
        "\n",
        "You can build an industry-specific chatbot by training it with relevant data. Additionally, the chatbot will remember user responses and continue building its internal graph structure to improve the responses that it can give."
      ],
      "metadata": {
        "id": "EBWwPtdpAhef"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ChatterBot"
      ],
      "metadata": {
        "id": "gxW4Jx5FvLUD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installs ChatterBot and its dependencies "
      ],
      "metadata": {
        "id": "9WJr9AcBByKZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "  pip install chatterbot==1.0.4 pytz"
      ],
      "metadata": {
        "id": "GMU9V6lHBsmU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Try the first conversation"
      ],
      "metadata": {
        "id": "CTBOPsNLB7v5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO name your chatbot\n",
        "chatbot_name = 'andrej'\n",
        "\n",
        "# TODO name your chatbot\n",
        "exit_conditions = (\":q\", \"quit\", \"exit\")\n"
      ],
      "metadata": {
        "id": "sicHz7QRkAFU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_WQ_paXGAAl_",
        "outputId": "a4965283-73be-4e73-9983-34973288db75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "> :q\n"
          ]
        }
      ],
      "source": [
        "from chatterbot import ChatBot\n",
        "\n",
        "chatbot = ChatBot(chatbot_name)\n",
        "\n",
        "while True:\n",
        "    query = input(\"> \")\n",
        "    if query in exit_conditions:\n",
        "        break\n",
        "    else:\n",
        "        print(f\"🪴 {chatbot.get_response(query)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Even if our chat-pot doesn’t have much to say yet, it’s already learning and growing.\n",
        "\n",
        "During the first run, ChatterBot created a SQLite database file where it stored all our inputs and connected them with possible responses. There should be three new files that have popped up in your working directory:\n",
        "\n",
        "\n",
        "```\n",
        "├── db.sqlite3\n",
        "├── db.sqlite3-shm\n",
        "└── db.sqlite3-wal\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "You can see the SQLite database on:\n",
        "https://inloop.github.io/sqlite-viewer/\n",
        "\n",
        "It is also possible to use another DB, for example MongoDB\n",
        "\n"
      ],
      "metadata": {
        "id": "rbKNSoe4C5yv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Make it little smarter\n",
        "\n",
        "https://chatterbot.readthedocs.io/en/stable/training.html#training-via-list-data"
      ],
      "metadata": {
        "id": "E1gQKFl5GN-_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from chatterbot import ChatBot\n",
        "from chatterbot.trainers import ListTrainer"
      ],
      "metadata": {
        "id": "KRp8R9CIDc40"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chatbot = ChatBot(chatbot_name)\n",
        "\n",
        "trainer = ListTrainer(chatbot)\n",
        "\n",
        "trainer.train([\n",
        "    \"Hi\",\n",
        "    \"Welcome, friend 🤗\",\n",
        "])\n",
        "\n",
        "# TODO Add another phrases\n",
        "trainer.train([\n",
        "    \"\",\n",
        "    \"\",\n",
        "])\n",
        "\n",
        "while True:\n",
        "    query = input(\"> \")\n",
        "    if query in exit_conditions:\n",
        "        break\n",
        "    else:\n",
        "        print(f\"🪴 {chatbot.get_response(query)}\")"
      ],
      "metadata": {
        "id": "tW6BbBOXGjKV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c4d14b7-2e18-4eaa-a3ca-9d03e029a1b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\rList Trainer: [##########          ] 50%"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "List Trainer: [####################] 100%\n",
            "List Trainer: [####################] 100%\n",
            "> :q\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using .train() injects entries into your database to build upon the graph structure that ChatterBot uses to choose possible replies.\n",
        "\n",
        "![Chatbot training](https://akela.mendelu.cz/~xgono/AI/chatbot_training.svg)\n",
        "\n",
        "If you pass an iterable with exactly two items to ListTrainer.train(), then ChatterBot considers the first item a statement and the second item an acceptable response.\n",
        "\n"
      ],
      "metadata": {
        "id": "4XC41TE8JrgS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocessors\n",
        "\n",
        "ChatterBot’s preprocessors are simple functions that modify the input statement that a chat bot receives before the statement gets processed by the logic adaper.\n",
        "\n",
        "ChatterBot comes with several built-in preprocessors.\n",
        "\n",
        "```\n",
        "chatbot = ChatBot(\n",
        "    'Bob the Bot',\n",
        "    preprocessors=[\n",
        "        'chatterbot.preprocessors.clean_whitespace'\n",
        "    ]\n",
        ")\n",
        "```\n",
        "\n",
        "### Logic Adapters\n",
        "\n",
        "Logic adapters determine the logic for how ChatterBot selects a response to a given input statement.\n",
        "\n",
        "The logic adapter that your bot uses can be specified by setting the logic_adapters parameter to the import path of the logic adapter you want to use.\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "chatbot = ChatBot(\n",
        "    \"My ChatterBot\",\n",
        "    logic_adapters=[\n",
        "        \"chatterbot.logic.BestMatch\"\n",
        "    ]\n",
        ")\n",
        "```\n",
        "\n",
        "![Chatbot training](https://akela.mendelu.cz/~xgono/AI/logic_adapters.svg)\n",
        "\n",
        "\n",
        "#### Best Match Adapter\n",
        "\n",
        "The best match adapter uses a function to compare the input statement to known statements. Once it finds the closest match to the input statement, it uses another function to select one of the known responses to that statement.\n",
        "\n",
        "\n",
        "#### Time Logic Adapter\n",
        "\n",
        "The TimeLogicAdapter identifies statements in which a question about the current time is asked. If a matching question is detected, then a response containing the current time is returned.\n",
        "\n",
        "```\n",
        "User: What time is it?\n",
        "Bot: The current time is 4:45PM.\n",
        "```\n",
        "\n",
        "#### Mathematical Evaluation Adapter\n",
        "\n",
        "The MathematicalEvaluation logic adapter checks a given statement to see if it contains a mathematical expression that can be evaluated. If one exists, then it returns a response containing the result. This adapter is able to handle any combination of word and numeric operators.\n",
        "\n",
        "```\n",
        "User: What is four plus four?\n",
        "Bot: (4 + 4) = 8\n",
        "```\n",
        "\n",
        "#### Specific Response Adapter\n",
        "\n",
        "If the input that the chat bot receives, matches the input text specified for this adapter, the specified response will be returned.\n",
        "\n",
        "```\n",
        "trainer.train([\n",
        "    'How can I help you?',\n",
        "    'I want to create a chat bot',\n",
        "    'Have you read the documentation?',\n",
        "    'No, I have not',\n",
        "    'This should help get you started: http://chatterbot.rtfd.org/en/latest/quickstart.html'\n",
        "])\n",
        "```\n",
        "\n",
        "```\n",
        "bot = ChatBot(\n",
        "    'Example Bot',\n",
        "    storage_adapter='chatterbot.storage.SQLStorageAdapter',\n",
        "    logic_adapters=[\n",
        "        {\n",
        "            'import_path': 'chatterbot.logic.BestMatch',\n",
        "            'default_response': 'I am sorry, but I do not understand.',\n",
        "            'maximum_similarity_threshold': 0.90\n",
        "        }\n",
        "    ]\n",
        ")\n",
        "```"
      ],
      "metadata": {
        "id": "9OQot0OIzWJn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The first step involves searching the database for a known statement that matches or closely matches the input statement. Once a match is selected, the second step involves selecting a known response to the selected match. Frequently, there will be a number of existing statements that are responses to the known match."
      ],
      "metadata": {
        "id": "QDBMhUHP43qn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can write your own logic adapters by creating a new class that inherits from LogicAdapter and overrides the necessary methods established in the LogicAdapter base class."
      ],
      "metadata": {
        "id": "wG7qElzH7IhN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Storage Adapters and text search\n",
        "\n",
        "Storage adapters provide an interface that allows ChatterBot to connect to different storage technologies.\n",
        "\n",
        "ChatterBot’s storage adapters support text search functionality. For example Bigram Text Index\n",
        "\n",
        "#### Bigram Text Index\n",
        "\n",
        "In addition, the generation of the pairs ensures that there is a smaller number of possible matches based on the probability of finding two neighboring words in an existing string that match the search parameter.\n",
        "\n",
        "For searches in larger data sets, the bigrams also reduce the number of OR comparisons that need to occur on a database level. This will always be a reduction of n - 1 where n is the number of search words.\n",
        "\n",
        "![Chatbot training](https://akela.mendelu.cz/~xgono/AI/bigrams.svg)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "yKPrFMpk7Wce"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Export a WhatsApp Chat"
      ],
      "metadata": {
        "id": "NeivV423LVJA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "chat_file = \"https://akela.mendelu.cz/~xgono/AI/chat.txt\"\n",
        "response = requests.get(chat_file)\n",
        "open(\"chat.txt\", \"wb\").write(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gcCASQGTnD1j",
        "outputId": "264ee3ec-6029-472e-ae49-b20ef48174d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9270"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can download a TXT file that contains the chat history of a WhatsApp conversation.\n",
        "\n",
        "---\n",
        "\n",
        "Example of exported WhatsApp chat\n",
        "\n",
        "```\n",
        "9/15/22, 14:50 - Messages and calls are end-to-end encrypted. No one outside of this chat, not even WhatsApp, can read or listen to them. Tap to learn more.\n",
        "9/15/22, 14:49 - Andrej: Hi Martin, Andrej here! Are you ready?\n",
        "9/15/22, 14:50 - Martin: Hello! Yes I'm ready.\n",
        "9/16/22, 06:34 - Martin: <Media omitted>\n",
        "\n",
        "```\n",
        "\n",
        "The format isn’t ideal to use for training.\n",
        "\n",
        "\n",
        "ChatterBot uses complete lines as messages when a chatbot replies to a user message. In the case of this chat export, it would therefore include all the message metadata. That means your chatbot would be studying the dates, times, and usernames! Not exactly great conversation fertilizer.\n",
        "\n"
      ],
      "metadata": {
        "id": "YnsJ_ChMLgv_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Clean our chat export"
      ],
      "metadata": {
        "id": "cZwOlalCmB7t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For example, you may notice that the first line of the provided chat export isn’t part of the conversation. Also, each actual message starts with metadata that includes a date, a time, and the username of the message sender.\n",
        "\n",
        "If you scroll further down the conversation file, you’ll find lines that aren’t real messages. Because you didn’t include media files in the chat export, WhatsApp replaced these files with the text <Media omitted>.\n",
        "\n"
      ],
      "metadata": {
        "id": "UHotwh4Y9ujb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def remove_chat_metadata(chat_export_file):\n",
        "    date_time = r\"(\\d+\\/\\d+\\/\\d+,\\s\\d+:\\d+)\"  # e.g. \"9/16/22, 06:34\"\n",
        "    dash_whitespace = r\"\\s-\\s\"  # \" - \"\n",
        "    username = r\"([\\w\\s]+)\"  # e.g. \"Martin\"\n",
        "    metadata_end = r\":\\s\"  # \": \"\n",
        "    pattern = date_time + dash_whitespace + username + metadata_end\n",
        "\n",
        "    with open(chat_export_file, \"r\") as corpus_file:\n",
        "        content = corpus_file.read()\n",
        "    cleaned_corpus = re.sub(pattern, \"\", content)\n",
        "    return tuple(cleaned_corpus.split(\"\\n\"))\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(remove_chat_metadata(\"chat.txt\"))"
      ],
      "metadata": {
        "id": "yx9LSFyBMePj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d48bd16-4318-41f3-ad04-49090d24aee9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('9/15/22, 14:50 - Messages and calls are end-to-end encrypted. No one outside of this chat, not even WhatsApp, can read or listen to them. Tap to learn more.', 'Hi Martin, Philipp here!', 'I’m ready to talk about plants!', \"Oh that's great!\", \"I've been waiting for a good convo about plants for a long time\", 'We all have.', 'Did you know they need water to grow?', 'I always thought that love and music was more than enough', 'But water makes sense', 'Do you talk to your plants?', 'I do!', 'Some of them even have names', 'What do they like to hear?', 'Motivational speeches', 'Or stories about plants that made it and are living outside now', 'Oohhh \\U0001f972', 'Are you training them for independence?', 'Yeah! I want them to be strong and take care of themselves at some point', \"That's heroic!\", \"Sounds like you're a great plant parent\", 'Do you have any plant care pro tips?', 'Ahh, idk i just leave them be...', 'They are doing ok but not great', 'So they are independent already!', \"I guess one tip would be to get plants that don't need much :P\", 'Like plastic plants, for example?', 'Haha, yes! Get independent plants!', 'Plastic plants are the cream of the crop', \"I haven't graduated to plastic plants yet\", 'Cream of the crop?', \"I don't know what this means\", 'Crop is a cultivated plant that is grown on a large scale commercially, especially a cereal, fruit, or vegetable', 'The cream must be the best of the best', 'Or maybe just all of it blended together? ;p', \"I don't grow any crop at home\", 'And no cream, in case you wondered', 'Ah, gotcha!', 'Let me show you something!', 'I let you', '<Media omitted>', \"It's a monsters!\", 'Monstera* (auto correct...)', 'I’m currently running an experiment of keeping my Monstera on the balcony', 'A monstera and a fluffy little monster', 'Haha, yeah, hard to tell which is which', 'How has it been going with the monstera on the balcony?', \"I've tried that too over the summer\", 'Pretty bad', 'Oh really?', 'What happened?', 'Yeah', 'I mean … it’s weird.', 'The leafs that she had are getting dryer and dryer. But she’s also growing plenty of new ones', 'It‘s like she’s changing her summer jacket to a winter jacket', 'Yeah something similar happened to ours', 'It had thrips over the winter, so we needed to get rid of them', \"Ah, thrips are those tiny little beasts that eat your plants, aren't they?\", 'Thought that the balcony time would help get rid of them', 'Yeah they are horrible, really cute and tiny and deadly', \"Most of the monstera's leaves died, but now there are new ones coming\", \"I think it's the amount of light, they need different leaves for stronger sunlight\", 'Do you have any other approaches to get rid of tiny monsters?', '(Except putting the plant on the balcony)', \"Tiny monstera's?\", 'Handling tiny monsters to grow big monsteras', 'Haha', 'Well, no. Just the balcony. This worked best', 'We tried applying soapy water', 'Which is a suggestion', \"And it keeps them a bit in check, but you can't get totally rid of them\", \"10/10 thrips don't like this simple trick 😅\", 'Oh, okay', \"8/10 thrips don't like this simple trick\", \"I really hope they're gone now 🤞\", 'Lol', \"It's depressing when lil monstera keeps making new leaves for them just to get infected 😢\", 'Yeah, nature can be harsh', \"Ah yes, it's a slightly strange rendering of nature though, if it's about potted plants\", 'I feel like they could handle it better out in the wild', \"Good that you're making yours strong enough to leave eventually!\", 'For the other plants, my words help them to grow', 'Inside and outside', 'What are the magic words?', 'Wait, do you make *all* plants grow???', 'Grow hastily, grow healthily, grow heartily \\U0001fa84✨🌱', 'Do you not make all your plants grow?', ':))', \"What do you consider 'your plants'?\", 'Oh, now I understand!', 'I only considered the plants that live in my apartment (or my balcony) as the plant-spell-receiving plants', 'But maybe they share the words?', 'Do raindrops touch their leaves?', \"I'm sure they chat with the other plants if they can\", 'Yeah, I heard that trees communicate in the woods with their roots', 'But thinking about that makes me feel bad that my plants are potted 😬', '😢', 'Yeah...', \"The trees use mushrooms mycelium in the ground that's hooked to their roots to chat\", 'Pretty cool 😎', 'So i also have a Pilea', 'And some basil plants', \"Do you have a photo of the Pilea? I don't know how it looks\", 'And a peace lily', 'https://en.m.wikipedia.org/wiki/Pilea_peperomioides', 'Oh, the Pilea looks cool!', 'The leaves are like small umbrellas', 'Did you actually manage to keep a supermarket basil alive or did you grow it yourself?', \"that's quite a story!\", 'my dad had a flowering basil last year and put the seeds from that one plant into seeding pots', 'so many of them came up that he had about two dining room tables full of basil plants, each in their own pots...', 'i got three of them, so they are second gen supermarket basils with lots of siblings :)', 'I always thought supermarket basil was meant to die after a few days', 'But it seems it was my subpar care', 'Congratulations to your basil dynasty!', 'Thanks!', 'Kudos go mostly to my dad', 'But you can bring them through winter', \"If there's no thrip infestation...\", '<Media omitted>', '<Media omitted>', '<Media omitted>', 'Morning view of most of my house plants', 'Fingers crossed 🤞', 'Are the ones on top avocados?', 'Yes, there are a couple of seedlings that wanted to live', 'Two more on the balcony of a similar size', \"And another seed that's one it's way 🤷\\u200d♂️\", 'I heard that it’s not easy to raise an Avodaco!', \"I haven't even heard of Avodacos!\", 'Wait, weren’t we talking about avocados?', 'Ah yes avocados 🥑!', 'I was just joking, riffing based on your typo 😝', 'Ooh! I was wondering why there was a red line under that word', 'Do you think there are avotacos? 🥑🌮', 'But I like that term, too', '😂', 'If this is not a common term, then I want to make it common!', 'Maybe growing an avotaco plant would be a plant symbiosis between an avocado tree and some corn plants?', 'Sounds like the perfect experiment!', '')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_non_message_text(export_text_lines):\n",
        "    messages = export_text_lines[1:-1]\n",
        "\n",
        "    filter_out_msgs = (\"<Media omitted>\",)\n",
        "    return tuple((msg for msg in messages if msg not in filter_out_msgs))\n",
        "\n",
        "def clean_corpus(chat_export_file):\n",
        "    message_corpus = remove_chat_metadata(chat_export_file)\n",
        "    cleaned_corpus = remove_non_message_text(message_corpus)\n",
        "    return cleaned_corpus"
      ],
      "metadata": {
        "id": "GYCPtpxOGmla"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_file = \"chat.txt\"\n",
        "\n",
        "chatbot = ChatBot(chatbot_name)\n",
        "\n",
        "trainer = ListTrainer(chatbot)\n",
        "cleaned_corpus = clean_corpus(corpus_file)\n",
        "trainer.train(cleaned_corpus)\n",
        "\n",
        "while True:\n",
        "    query = input(\"> \")\n",
        "    if query in exit_conditions:\n",
        "        break\n",
        "    else:\n",
        "        print(f\"🪴 {chatbot.get_response(query)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "muDQ8bamDYTL",
        "outputId": "a92e5b60-e11c-49af-867a-401820961359"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "List Trainer: [#                   ] 7%"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "List Trainer: [####################] 100%\n",
            "> :q\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://chatterbot.readthedocs.io/en/stable/logic/index.html#logic-adapters\n"
      ],
      "metadata": {
        "id": "iCHAAz77E9v-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ChatBot with Deep Learning Model"
      ],
      "metadata": {
        "id": "IgzQg4bNa1eg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For this purpose, we will use the nltk (Natural Language Toolkit), which contains a whole bunch of tools for cleaning up text and preparing it for deep learning algorithms.\n",
        "\n",
        "…And keras, which is the deep learning framework we’ll be using."
      ],
      "metadata": {
        "id": "yF9bfrYabWTK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "import json\n",
        "import pickle\n",
        "\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout\n",
        "from keras.optimizers import SGD\n",
        "import random"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SxA5Ra-GbQr1",
        "outputId": "14144d61-aa88-45aa-dd2f-985847d6eb1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "url = \"https://akela.mendelu.cz/~xgono/AI/intents.json\"\n",
        "\n",
        "response = requests.get(url)\n",
        "open(\"intents.json\", \"wb\").write(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8LKavyEcfTi",
        "outputId": "53bc8712-0f9e-4b4a-b3f0-e1ae089982d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12310"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words=[]\n",
        "classes = []\n",
        "documents = []\n",
        "ignore_words = ['?', '!']\n",
        "data_file = open('intents.json').read()\n",
        "intents = json.loads(data_file)"
      ],
      "metadata": {
        "id": "1jzX3ehWbffG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "```\n",
        "intents\": [\n",
        "    {\n",
        "          \"tag\": \"greeting\",\n",
        "            \"patterns\": [\n",
        "                \"Hi there\",\n",
        "                \"How are you\",\n",
        "                \"Is anyone there?\",\n",
        "                \"Hey\",\n",
        "                \"Hola\",\n",
        "                \"Hello\",\n",
        "                \"Good day\",\n",
        "                \"Namaste\",\n",
        "                \"yo\"\n",
        "            ],\n",
        "            \"responses\": [\n",
        "                \"Hello\",\n",
        "                \"Good to see you again\",\n",
        "                \"Hi there, how can I help?\"\n",
        "            ],\n",
        "            \"context\": [\n",
        "                \"\"\n",
        "            ]\n",
        "        },\n",
        "    {\n",
        "            \"tag\": \"jokes\",\n",
        "            \"patterns\": [\n",
        "                \"Tell me a joke\",\n",
        "                \"Joke\",\n",
        "                \"Make me laugh\"\n",
        "            ],\n",
        "            \"responses\": [\n",
        "                \"A perfectionist walked into a bar...apparently, the bar wasn't set high enough\",\n",
        "                \"I ate a clock yesterday, it was very time-consuming\",\n",
        "                \"Never criticize someone until you've walked a mile in their shoes. That way, when you criticize them, they won't be able to hear you from that far away. Plus, you'll have their shoes.\",\n",
        "                \"The world tongue-twister champion just got arrested. I hear they're gonna give him a really tough sentence.\",\n",
        "                \"I own the world's worst thesaurus. Not only is it awful, it's awful.\",\n",
        "                \"What did the traffic light say to the car? \\\"Don't look now, I'm changing.\\\"\",\n",
        "                \"What do you call a snowman with a suntan? A puddle.\",\n",
        "                \"How does a penguin build a house? Igloos it together\",\n",
        "                \"I went to see the doctor about my short-term memory problems – the first thing he did was make me pay in advance\",\n",
        "                \"As I get older and I remember all the people I’ve lost along the way, I think to myself, maybe a career as a tour guide wasn’t for me.\",\n",
        "                \"o what if I don't know what 'Armageddon' means? It's not the end of the world.\"\n",
        "            ],\n",
        "            \"context\": [\n",
        "                \"jokes\"\n",
        "            ]\n",
        "        },\n",
        "]\n",
        "    \n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "Aj4nkkL0eP1i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for intent in intents['intents']:\n",
        "    for pattern in intent['patterns']:\n",
        "\n",
        "        # take each word and tokenize it\n",
        "        w = nltk.word_tokenize(pattern)\n",
        "        words.extend(w)\n",
        "        \n",
        "        # adding documents\n",
        "        documents.append((w, intent['tag']))\n",
        "\n",
        "        # adding classes to our class list\n",
        "        if intent['tag'] not in classes:\n",
        "            classes.append(intent['tag'])\n",
        "\n",
        "words = [lemmatizer.lemmatize(w.lower()) for w in words if w not in ignore_words]\n",
        "words = sorted(list(set(words)))\n",
        "\n",
        "classes = sorted(list(set(classes)))\n",
        "\n",
        "print (len(documents), \"documents\", documents)\n",
        "\n",
        "print (len(classes), \"classes\", classes)\n",
        "\n",
        "print (len(words), \"unique lemmatized words\", words)\n",
        "\n",
        "\n",
        "pickle.dump(words,open('words.pkl','wb'))\n",
        "pickle.dump(classes,open('classes.pkl','wb'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z5MgJ0G6d5sI",
        "outputId": "0d21990d-e974-4c6f-d01d-703539bec023"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "113 documents [(['google'], 'google'), (['search'], 'google'), (['internet'], 'google'), (['Hi', 'there'], 'greeting'), (['How', 'are', 'you'], 'greeting'), (['Is', 'anyone', 'there', '?'], 'greeting'), (['Hey'], 'greeting'), (['Hola'], 'greeting'), (['Hello'], 'greeting'), (['Good', 'day'], 'greeting'), (['Namaste'], 'greeting'), (['yo'], 'greeting'), (['Bye'], 'goodbye'), (['See', 'you', 'later'], 'goodbye'), (['Goodbye'], 'goodbye'), (['Get', 'lost'], 'goodbye'), (['Till', 'next', 'time'], 'goodbye'), (['bbye'], 'goodbye'), (['Thanks'], 'thanks'), (['Thank', 'you'], 'thanks'), (['That', \"'s\", 'helpful'], 'thanks'), (['Awesome', ',', 'thanks'], 'thanks'), (['Thanks', 'for', 'helping', 'me'], 'thanks'), (['How', 'you', 'could', 'help', 'me', '?'], 'options'), (['What', 'you', 'can', 'do', '?'], 'options'), (['What', 'help', 'you', 'provide', '?'], 'options'), (['How', 'you', 'can', 'be', 'helpful', '?'], 'options'), (['What', 'support', 'is', 'offered'], 'options'), (['Tell', 'me', 'a', 'joke'], 'jokes'), (['Joke'], 'jokes'), (['Make', 'me', 'laugh'], 'jokes'), (['Who', 'are', 'you'], 'Identity'), (['what', 'are', 'you'], 'Identity'), (['What', 'is', 'the', 'time'], 'datetime'), (['what', 'is', 'the', 'date'], 'datetime'), (['date'], 'datetime'), (['time'], 'datetime'), (['tell', 'me', 'the', 'date'], 'datetime'), (['day'], 'datetime'), (['what', 'day', 'is', 'is', 'today'], 'datetime'), (['Whats', 'up'], 'whatsup'), (['Wazzup'], 'whatsup'), (['How', 'are', 'you'], 'whatsup'), (['sup'], 'whatsup'), (['How', 'you', 'doing'], 'whatsup'), (['haha'], 'haha'), (['lol'], 'haha'), (['rofl'], 'haha'), (['lmao'], 'haha'), (['thats', 'funny'], 'haha'), (['Who', 'made', 'you'], 'programmer'), (['who', 'designed', 'you'], 'programmer'), (['who', 'programmed', 'you'], 'programmer'), (['you', 'are', 'dumb'], 'insult'), (['shut', 'up'], 'insult'), (['idiot'], 'insult'), (['what', 'are', 'you', 'doing'], 'activity'), (['what', 'are', 'you', 'upto'], 'activity'), (['Awesome'], 'exclaim'), (['Great'], 'exclaim'), (['I', 'know'], 'exclaim'), (['ok'], 'exclaim'), (['yeah'], 'exclaim'), (['temperature'], 'weather'), (['weather'], 'weather'), (['how', 'hot', 'is', 'it'], 'weather'), (['who', 'is', 'he'], 'karan'), (['who', 'is', 'that'], 'karan'), (['who', 'is', 'karan'], 'karan'), (['karan', 'malik'], 'karan'), (['contact', 'developer'], 'contact'), (['contact', 'karan'], 'contact'), (['contact', 'programmer'], 'contact'), (['contact', 'creator'], 'contact'), (['You', 'are', 'awesome'], 'appreciate'), (['you', 'are', 'the', 'best'], 'appreciate'), (['you', 'are', 'great'], 'appreciate'), (['you', 'are', 'good'], 'appreciate'), (['it', 'was', 'nice', 'talking', 'to', 'you'], 'nicetty'), (['good', 'talk'], 'nicetty'), (['no'], 'no'), (['nope'], 'no'), (['news'], 'news'), (['latest', 'news'], 'news'), (['india', 'news'], 'news'), (['who', 'inspires', 'you'], 'inspire'), (['who', 'is', 'your', 'inspiration'], 'inspire'), (['who', 'motivates', 'you'], 'inspire'), (['current', 'cricket', 'matches'], 'cricket'), (['cricket', 'score'], 'cricket'), (['top', 'songs'], 'song'), (['best', 'songs'], 'song'), (['hot', 'songs'], 'song'), (['top', '10', 'songs'], 'song'), (['top', 'ten', 'songs'], 'song'), (['i', 'am', 'good'], 'greetreply'), (['I', \"'m\", 'good'], 'greetreply'), (['i', 'am', 'fine'], 'greetreply'), (['i', \"'m\", 'fine'], 'greetreply'), (['good'], 'greetreply'), (['set', 'a', 'timer'], 'timer'), (['covid', '19'], 'covid19'), (['you', 'are', 'useless'], 'suggest'), (['useless'], 'suggest'), (['suggest'], 'suggest'), (['suggestions'], 'suggest'), (['you', 'are', 'bad'], 'suggest'), (['Ask', 'me', 'a', 'riddle'], 'riddle'), (['Ask', 'me', 'a', 'question'], 'riddle'), (['Riddle'], 'riddle'), (['how', 'old', 'are', 'you'], 'age'), (['when', 'were', 'you', 'made'], 'age'), (['what', 'is', 'your', 'age'], 'age')]\n",
            "30 classes ['Identity', 'activity', 'age', 'appreciate', 'contact', 'covid19', 'cricket', 'datetime', 'exclaim', 'goodbye', 'google', 'greeting', 'greetreply', 'haha', 'inspire', 'insult', 'jokes', 'karan', 'news', 'nicetty', 'no', 'options', 'programmer', 'riddle', 'song', 'suggest', 'thanks', 'timer', 'weather', 'whatsup']\n",
            "130 unique lemmatized words [\"'m\", \"'s\", ',', '10', '19', 'a', 'age', 'am', 'anyone', 'are', 'ask', 'awesome', 'bad', 'bbye', 'be', 'best', 'bye', 'can', 'contact', 'could', 'covid', 'creator', 'cricket', 'current', 'date', 'day', 'designed', 'developer', 'do', 'doing', 'dumb', 'fine', 'for', 'funny', 'get', 'good', 'goodbye', 'google', 'great', 'haha', 'he', 'hello', 'help', 'helpful', 'helping', 'hey', 'hi', 'hola', 'hot', 'how', 'i', 'idiot', 'india', 'inspiration', 'inspires', 'internet', 'is', 'it', 'joke', 'karan', 'know', 'later', 'latest', 'laugh', 'lmao', 'lol', 'lost', 'made', 'make', 'malik', 'match', 'me', 'motivates', 'namaste', 'news', 'next', 'nice', 'no', 'nope', 'offered', 'ok', 'old', 'programmed', 'programmer', 'provide', 'question', 'riddle', 'rofl', 'score', 'search', 'see', 'set', 'shut', 'song', 'suggest', 'suggestion', 'sup', 'support', 'talk', 'talking', 'tell', 'temperature', 'ten', 'thank', 'thanks', 'that', 'thats', 'the', 'there', 'till', 'time', 'timer', 'to', 'today', 'top', 'up', 'upto', 'useless', 'wa', 'wazzup', 'weather', 'were', 'what', 'whats', 'when', 'who', 'yeah', 'yo', 'you', 'your']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Building the Deep Learning Model"
      ],
      "metadata": {
        "id": "LKHJKL88f_sG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# initializing training data\n",
        "training = []\n",
        "output_empty = [0] * len(classes)\n",
        "\n",
        "for doc in documents:\n",
        "\n",
        "    # initializing bag of words\n",
        "    bag = []\n",
        "\n",
        "    # list of tokenized words for the pattern\n",
        "    pattern_words = doc[0]\n",
        "\n",
        "    # lemmatize each word - create base word, in attempt to represent related words\n",
        "    pattern_words = [lemmatizer.lemmatize(word.lower()) for word in pattern_words]\n",
        "\n",
        "    # create our bag of words array with 1, if word match found in current pattern\n",
        "    for w in words:\n",
        "        bag.append(1) if w in pattern_words else bag.append(0)\n",
        "\n",
        "    # output is a '0' for each tag and '1' for current tag (for each pattern)\n",
        "    output_row = list(output_empty)\n",
        "    output_row[classes.index(doc[1])] = 1\n",
        "\n",
        "    training.append([bag, output_row])\n",
        "    \n",
        "# shuffle our features and turn into np.array\n",
        "random.shuffle(training)\n",
        "training = np.array(training)\n",
        "\n",
        "# create train and test lists. X - patterns, Y - intents\n",
        "train_x = list(training[:,0])\n",
        "train_y = list(training[:,1])\n",
        "print(\"Training data created\")"
      ],
      "metadata": {
        "id": "_VArSjjBgD4g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The **Dropout** effect is that the network becomes less sensitive to the specific weights of neurons. This, in turn, results in a network capable of better generalization and less likely to overfit the training data. Dropout is only used during the training of a model and is not used when evaluating the skill of the model. \n",
        "\n",
        "\n",
        "**Sigmoid** is used for binary classification methods where we only have 2 classes, while SoftMax applies to multiclass problems. In fact, the SoftMax function is an extension of the Sigmoid function."
      ],
      "metadata": {
        "id": "vnn6W4GPAoGD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "qST2l4gpA2AZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create model - 3 layers. First layer 128 neurons, second layer 64 neurons and 3rd output layer contains number of neurons\n",
        "# equal to number of intents to predict output intent with softmax\n",
        "model = Sequential()\n",
        "model.add(Dense(128, input_shape=(len(train_x[0]),), activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(len(train_y[0]), activation='softmax'))\n",
        "\n",
        "# Compile model. Stochastic gradient descent with Nesterov accelerated gradient gives good results for this model\n",
        "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
        "\n",
        "#fitting and saving the model\n",
        "hist = model.fit(np.array(train_x), np.array(train_y), epochs=200, batch_size=5, verbose=1)\n",
        "model.save('chatbot_model.h5', hist)\n",
        "\n",
        "print(\"model created\")"
      ],
      "metadata": {
        "id": "HZS2pU-niFG0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aea866ae-d88c-4e6f-e85b-54c0b7403a6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "23/23 [==============================] - 1s 2ms/step - loss: 3.4204 - accuracy: 0.0265 \n",
            "Epoch 2/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 3.3743 - accuracy: 0.0708\n",
            "Epoch 3/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 3.3120 - accuracy: 0.1150\n",
            "Epoch 4/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 3.2850 - accuracy: 0.0885\n",
            "Epoch 5/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 3.2266 - accuracy: 0.1239\n",
            "Epoch 6/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 3.1754 - accuracy: 0.1150\n",
            "Epoch 7/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 3.0958 - accuracy: 0.1770\n",
            "Epoch 8/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 3.0300 - accuracy: 0.1947\n",
            "Epoch 9/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 2.9965 - accuracy: 0.2212\n",
            "Epoch 10/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 2.8011 - accuracy: 0.2566\n",
            "Epoch 11/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 2.7981 - accuracy: 0.2389\n",
            "Epoch 12/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 2.6042 - accuracy: 0.2832\n",
            "Epoch 13/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 2.4826 - accuracy: 0.3628\n",
            "Epoch 14/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 2.4061 - accuracy: 0.3274\n",
            "Epoch 15/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 2.2771 - accuracy: 0.3363\n",
            "Epoch 16/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 2.1129 - accuracy: 0.3894\n",
            "Epoch 17/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 2.1121 - accuracy: 0.3628\n",
            "Epoch 18/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 2.0035 - accuracy: 0.4867\n",
            "Epoch 19/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 1.8135 - accuracy: 0.5044\n",
            "Epoch 20/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 1.8223 - accuracy: 0.5398\n",
            "Epoch 21/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 1.6906 - accuracy: 0.5044\n",
            "Epoch 22/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.7010 - accuracy: 0.4867\n",
            "Epoch 23/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 1.6516 - accuracy: 0.5221\n",
            "Epoch 24/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 1.4882 - accuracy: 0.5752\n",
            "Epoch 25/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 1.5005 - accuracy: 0.6018\n",
            "Epoch 26/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 1.3053 - accuracy: 0.6460\n",
            "Epoch 27/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 1.3088 - accuracy: 0.6549\n",
            "Epoch 28/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 1.3886 - accuracy: 0.5575\n",
            "Epoch 29/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 1.3505 - accuracy: 0.6106\n",
            "Epoch 30/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 1.2025 - accuracy: 0.6814\n",
            "Epoch 31/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 1.1931 - accuracy: 0.6991\n",
            "Epoch 32/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 1.0260 - accuracy: 0.6991\n",
            "Epoch 33/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.9022 - accuracy: 0.7522\n",
            "Epoch 34/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.9174 - accuracy: 0.7257\n",
            "Epoch 35/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.8631 - accuracy: 0.7611\n",
            "Epoch 36/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.9381 - accuracy: 0.7345\n",
            "Epoch 37/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.9992 - accuracy: 0.6991\n",
            "Epoch 38/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.9319 - accuracy: 0.7257\n",
            "Epoch 39/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6040 - accuracy: 0.8496\n",
            "Epoch 40/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.8945 - accuracy: 0.7168\n",
            "Epoch 41/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6270 - accuracy: 0.8496\n",
            "Epoch 42/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6710 - accuracy: 0.8053\n",
            "Epoch 43/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6871 - accuracy: 0.7965\n",
            "Epoch 44/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6733 - accuracy: 0.7965\n",
            "Epoch 45/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.7189 - accuracy: 0.7434\n",
            "Epoch 46/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5892 - accuracy: 0.8673\n",
            "Epoch 47/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6215 - accuracy: 0.8319\n",
            "Epoch 48/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6281 - accuracy: 0.8319\n",
            "Epoch 49/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.7044 - accuracy: 0.7611\n",
            "Epoch 50/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5173 - accuracy: 0.9027\n",
            "Epoch 51/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6226 - accuracy: 0.8230\n",
            "Epoch 52/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4783 - accuracy: 0.8584\n",
            "Epoch 53/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4714 - accuracy: 0.8407\n",
            "Epoch 54/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4888 - accuracy: 0.8761\n",
            "Epoch 55/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4837 - accuracy: 0.8584\n",
            "Epoch 56/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5505 - accuracy: 0.8230\n",
            "Epoch 57/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.8673\n",
            "Epoch 58/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.3121 - accuracy: 0.9292\n",
            "Epoch 59/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5306 - accuracy: 0.8407\n",
            "Epoch 60/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4041 - accuracy: 0.8850\n",
            "Epoch 61/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.3421 - accuracy: 0.9204\n",
            "Epoch 62/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4400 - accuracy: 0.8584\n",
            "Epoch 63/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4921 - accuracy: 0.8496\n",
            "Epoch 64/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4153 - accuracy: 0.8673\n",
            "Epoch 65/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4708 - accuracy: 0.8673\n",
            "Epoch 66/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.3711 - accuracy: 0.9115\n",
            "Epoch 67/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4309 - accuracy: 0.8850\n",
            "Epoch 68/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4062 - accuracy: 0.8673\n",
            "Epoch 69/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.3209 - accuracy: 0.8938\n",
            "Epoch 70/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.2834 - accuracy: 0.9115\n",
            "Epoch 71/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.2787 - accuracy: 0.9292\n",
            "Epoch 72/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4768 - accuracy: 0.8407\n",
            "Epoch 73/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.3596 - accuracy: 0.9027\n",
            "Epoch 74/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4168 - accuracy: 0.8407\n",
            "Epoch 75/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.3124 - accuracy: 0.8938\n",
            "Epoch 76/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.3727 - accuracy: 0.8496\n",
            "Epoch 77/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.3681 - accuracy: 0.8938\n",
            "Epoch 78/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4184 - accuracy: 0.8673\n",
            "Epoch 79/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.2916 - accuracy: 0.9292\n",
            "Epoch 80/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.2922 - accuracy: 0.9115\n",
            "Epoch 81/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1819 - accuracy: 0.9646\n",
            "Epoch 82/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.2646 - accuracy: 0.9204\n",
            "Epoch 83/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.2765 - accuracy: 0.9381\n",
            "Epoch 84/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.2714 - accuracy: 0.9204\n",
            "Epoch 85/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.3946 - accuracy: 0.8938\n",
            "Epoch 86/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.2827 - accuracy: 0.9204\n",
            "Epoch 87/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.3060 - accuracy: 0.9204\n",
            "Epoch 88/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.2090 - accuracy: 0.9292\n",
            "Epoch 89/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.3084 - accuracy: 0.9204\n",
            "Epoch 90/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.2512 - accuracy: 0.9381\n",
            "Epoch 91/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.3162 - accuracy: 0.9204\n",
            "Epoch 92/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.3534 - accuracy: 0.8938\n",
            "Epoch 93/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.3500 - accuracy: 0.8850\n",
            "Epoch 94/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.2492 - accuracy: 0.9204\n",
            "Epoch 95/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.3001 - accuracy: 0.9292\n",
            "Epoch 96/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.3547 - accuracy: 0.8673\n",
            "Epoch 97/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.2322 - accuracy: 0.9027\n",
            "Epoch 98/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.2196 - accuracy: 0.9292\n",
            "Epoch 99/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1611 - accuracy: 0.9646\n",
            "Epoch 100/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.2349 - accuracy: 0.9292\n",
            "Epoch 101/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.2842 - accuracy: 0.9204\n",
            "Epoch 102/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.2027 - accuracy: 0.9204\n",
            "Epoch 103/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.2298 - accuracy: 0.9292\n",
            "Epoch 104/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1724 - accuracy: 0.9646\n",
            "Epoch 105/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1730 - accuracy: 0.9558\n",
            "Epoch 106/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.2482 - accuracy: 0.9381\n",
            "Epoch 107/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.2253 - accuracy: 0.9381\n",
            "Epoch 108/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.3334 - accuracy: 0.8938\n",
            "Epoch 109/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.2383 - accuracy: 0.9292\n",
            "Epoch 110/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.2936 - accuracy: 0.8761\n",
            "Epoch 111/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.2410 - accuracy: 0.9469\n",
            "Epoch 112/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.2326 - accuracy: 0.9027\n",
            "Epoch 113/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.2382 - accuracy: 0.9469\n",
            "Epoch 114/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.2698 - accuracy: 0.8850\n",
            "Epoch 115/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1720 - accuracy: 0.9646\n",
            "Epoch 116/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.2284 - accuracy: 0.8938\n",
            "Epoch 117/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.2406 - accuracy: 0.9292\n",
            "Epoch 118/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1518 - accuracy: 0.9558\n",
            "Epoch 119/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.2282 - accuracy: 0.9381\n",
            "Epoch 120/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1901 - accuracy: 0.9381\n",
            "Epoch 121/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1927 - accuracy: 0.9381\n",
            "Epoch 122/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1641 - accuracy: 0.9292\n",
            "Epoch 123/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1707 - accuracy: 0.9558\n",
            "Epoch 124/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1442 - accuracy: 0.9646\n",
            "Epoch 125/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.2611 - accuracy: 0.8850\n",
            "Epoch 126/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.0950 - accuracy: 0.9823\n",
            "Epoch 127/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1440 - accuracy: 0.9735\n",
            "Epoch 128/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1827 - accuracy: 0.9646\n",
            "Epoch 129/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1699 - accuracy: 0.9735\n",
            "Epoch 130/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1939 - accuracy: 0.9204\n",
            "Epoch 131/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1049 - accuracy: 0.9735\n",
            "Epoch 132/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.2365 - accuracy: 0.9292\n",
            "Epoch 133/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1644 - accuracy: 0.9558\n",
            "Epoch 134/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.2132 - accuracy: 0.9292\n",
            "Epoch 135/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1988 - accuracy: 0.9469\n",
            "Epoch 136/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1966 - accuracy: 0.9558\n",
            "Epoch 137/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1791 - accuracy: 0.9469\n",
            "Epoch 138/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1811 - accuracy: 0.9292\n",
            "Epoch 139/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1144 - accuracy: 0.9823\n",
            "Epoch 140/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1250 - accuracy: 0.9823\n",
            "Epoch 141/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1542 - accuracy: 0.9558\n",
            "Epoch 142/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.2489 - accuracy: 0.9381\n",
            "Epoch 143/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1980 - accuracy: 0.9292\n",
            "Epoch 144/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1418 - accuracy: 0.9558\n",
            "Epoch 145/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.2110 - accuracy: 0.9292\n",
            "Epoch 146/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1851 - accuracy: 0.9469\n",
            "Epoch 147/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1503 - accuracy: 0.9469\n",
            "Epoch 148/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1182 - accuracy: 0.9646\n",
            "Epoch 149/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1505 - accuracy: 0.9558\n",
            "Epoch 150/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1600 - accuracy: 0.9381\n",
            "Epoch 151/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1750 - accuracy: 0.9204\n",
            "Epoch 152/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1609 - accuracy: 0.9381\n",
            "Epoch 153/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1557 - accuracy: 0.9558\n",
            "Epoch 154/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.2084 - accuracy: 0.9292\n",
            "Epoch 155/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.0947 - accuracy: 0.9823\n",
            "Epoch 156/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1852 - accuracy: 0.9292\n",
            "Epoch 157/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1603 - accuracy: 0.9735\n",
            "Epoch 158/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1883 - accuracy: 0.9292\n",
            "Epoch 159/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1221 - accuracy: 0.9558\n",
            "Epoch 160/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.0766 - accuracy: 0.9735\n",
            "Epoch 161/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1084 - accuracy: 0.9646\n",
            "Epoch 162/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.0694 - accuracy: 0.9735\n",
            "Epoch 163/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1791 - accuracy: 0.9469\n",
            "Epoch 164/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1382 - accuracy: 0.9646\n",
            "Epoch 165/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.2159 - accuracy: 0.9204\n",
            "Epoch 166/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.0962 - accuracy: 0.9646\n",
            "Epoch 167/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2203 - accuracy: 0.9204\n",
            "Epoch 168/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2207 - accuracy: 0.9381\n",
            "Epoch 169/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.1196 - accuracy: 0.9735\n",
            "Epoch 170/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.1823 - accuracy: 0.9292\n",
            "Epoch 171/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.1250 - accuracy: 0.9646\n",
            "Epoch 172/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.1463 - accuracy: 0.9469\n",
            "Epoch 173/200\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1207 - accuracy: 0.9646\n",
            "Epoch 174/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.1361 - accuracy: 0.9558\n",
            "Epoch 175/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.1023 - accuracy: 0.9558\n",
            "Epoch 176/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.0990 - accuracy: 0.9735\n",
            "Epoch 177/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2039 - accuracy: 0.9381\n",
            "Epoch 178/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.1861 - accuracy: 0.9469\n",
            "Epoch 179/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.1687 - accuracy: 0.9381\n",
            "Epoch 180/200\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2757 - accuracy: 0.8850\n",
            "Epoch 181/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.1524 - accuracy: 0.9381\n",
            "Epoch 182/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.0881 - accuracy: 0.9823\n",
            "Epoch 183/200\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2043 - accuracy: 0.9558\n",
            "Epoch 184/200\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.1249 - accuracy: 0.9558\n",
            "Epoch 185/200\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.1379 - accuracy: 0.9646\n",
            "Epoch 186/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.1443 - accuracy: 0.9646\n",
            "Epoch 187/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.1300 - accuracy: 0.9646\n",
            "Epoch 188/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.1203 - accuracy: 0.9469\n",
            "Epoch 189/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.0617 - accuracy: 0.9912\n",
            "Epoch 190/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1656 - accuracy: 0.9558\n",
            "Epoch 191/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1163 - accuracy: 0.9558\n",
            "Epoch 192/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.0854 - accuracy: 0.9912\n",
            "Epoch 193/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1055 - accuracy: 0.9735\n",
            "Epoch 194/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1444 - accuracy: 0.9646\n",
            "Epoch 195/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1270 - accuracy: 0.9646\n",
            "Epoch 196/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1194 - accuracy: 0.9558\n",
            "Epoch 197/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1751 - accuracy: 0.9381\n",
            "Epoch 198/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1023 - accuracy: 0.9646\n",
            "Epoch 199/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1256 - accuracy: 0.9558\n",
            "Epoch 200/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1606 - accuracy: 0.9469\n",
            "model created\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we have our training and test data ready and we can now use a deep learning model from keras called Sequential.\n",
        "\n",
        "The Sequential model in keras is actually one of the simplest neural networks, a multi-layer perceptron. This particular network has 3 layers, with the first one having 128 neurons, the second one having 64 neurons, and the third one having the number of intents as the number of neurons. Remember, the point of this network is to be able to predict which intent to choose given some data.\n",
        "\n",
        "The model will be trained with stochastic gradient descent. Stochastic gradient descent is more efficient than normal gradient descent.\n",
        "\n",
        "After the model is trained, the whole thing is turned into a numpy array and saved as chatbot_model.h5.\n",
        "\n",
        "We will use this model to form our chatbot interface."
      ],
      "metadata": {
        "id": "8n_kUh1IjvVT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create"
      ],
      "metadata": {
        "id": "PPRJTeuxl5Y7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "model = load_model('chatbot_model.h5')\n",
        "import json\n",
        "import random\n",
        "intents = json.loads(open('intents.json').read())\n",
        "words = pickle.load(open('words.pkl','rb'))\n",
        "classes = pickle.load(open('classes.pkl','rb'))"
      ],
      "metadata": {
        "id": "J2rybWSCmEwd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_up_sentence(sentence):\n",
        "    sentence_words = nltk.word_tokenize(sentence)\n",
        "    sentence_words = [lemmatizer.lemmatize(word.lower()) for word in sentence_words]\n",
        "    return sentence_words\n",
        "\n",
        "# return bag of words array: 0 or 1 for each word in the bag that exists in the sentence\n",
        "\n",
        "def bow(sentence, words, show_details=True):\n",
        "    # tokenize the pattern\n",
        "    sentence_words = clean_up_sentence(sentence)\n",
        "    # bag of words - matrix of N words, vocabulary matrix\n",
        "    bag = [0]*len(words)\n",
        "    for s in sentence_words:\n",
        "        for i,w in enumerate(words):\n",
        "            if w == s:\n",
        "                # assign 1 if current word is in the vocabulary position\n",
        "                bag[i] = 1\n",
        "                if show_details:\n",
        "                    print (\"found in bag: %s\" % w)\n",
        "    return(np.array(bag))\n",
        "\n",
        "def predict_class(sentence, model):\n",
        "    # filter out predictions below a threshold\n",
        "    p = bow(sentence, words,show_details=False)\n",
        "    res = model.predict(np.array([p]))[0]\n",
        "    ERROR_THRESHOLD = 0.25\n",
        "    results = [[i,r] for i,r in enumerate(res) if r>ERROR_THRESHOLD]\n",
        "    # sort by strength of probability\n",
        "    results.sort(key=lambda x: x[1], reverse=True)\n",
        "    return_list = []\n",
        "    for r in results:\n",
        "        return_list.append({\"intent\": classes[r[0]], \"probability\": str(r[1])})\n",
        "    return return_list\n",
        "\n",
        "def getResponse(ints, intents_json):\n",
        "    tag = ints[0]['intent']\n",
        "    list_of_intents = intents_json['intents']\n",
        "    for i in list_of_intents:\n",
        "        if(i['tag']== tag):\n",
        "            result = random.choice(i['responses'])\n",
        "            break\n",
        "    return result\n",
        "\n",
        "def chatbot_response(msg):\n",
        "    ints = predict_class(msg, model)\n",
        "    res = getResponse(ints, intents)\n",
        "    return res"
      ],
      "metadata": {
        "id": "a4hO7nHWnBOc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "    query = input(\"> \")\n",
        "    if query in exit_conditions:\n",
        "        break\n",
        "    else:\n",
        "        res = chatbot_response(query)\n",
        "        print(res)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gh-qAdiYnGeP",
        "outputId": "412b524e-0f1f-427a-8a76-3952f8d7aa45"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "> :q\n"
          ]
        }
      ]
    }
  ]
}