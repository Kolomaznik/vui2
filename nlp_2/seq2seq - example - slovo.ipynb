{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of slovo_slovo_cz_cz.ipynb","provenance":[{"file_id":"15xJZv46QKpoV9oL6U4w-SsA8LHRhiry9","timestamp":1607266338814}],"authorship_tag":"ABX9TyORD5jhz4JELsDrsUw8vj9/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i7WNILDD_o-a","executionInfo":{"status":"ok","timestamp":1607261472310,"user_tz":-60,"elapsed":8490,"user":{"displayName":"Peter Chochula","photoUrl":"","userId":"03128571225950042155"}},"outputId":"091b5d95-69fa-47f1-91b3-a8f603a4846a"},"source":["!pip install unidecode\n","!pip install revtok"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting unidecode\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/42/d9edfed04228bacea2d824904cae367ee9efd05e6cce7ceaaedd0b0ad964/Unidecode-1.1.1-py2.py3-none-any.whl (238kB)\n","\r\u001b[K     |█▍                              | 10kB 18.6MB/s eta 0:00:01\r\u001b[K     |██▊                             | 20kB 16.1MB/s eta 0:00:01\r\u001b[K     |████▏                           | 30kB 14.9MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 40kB 13.5MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 51kB 11.2MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 61kB 10.8MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 71kB 11.2MB/s eta 0:00:01\r\u001b[K     |███████████                     | 81kB 12.2MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 92kB 11.3MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 102kB 10.7MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 112kB 10.7MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 122kB 10.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 133kB 10.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 143kB 10.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 153kB 10.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 163kB 10.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 174kB 10.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 184kB 10.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 194kB 10.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 204kB 10.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 215kB 10.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 225kB 10.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 235kB 10.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 245kB 10.7MB/s \n","\u001b[?25hInstalling collected packages: unidecode\n","Successfully installed unidecode-1.1.1\n","Collecting revtok\n","  Downloading https://files.pythonhosted.org/packages/83/36/ceaee3090850fe4940361110cae71091b113c720e4ced21660758da6ced1/revtok-0.0.3-py3-none-any.whl\n","Installing collected packages: revtok\n","Successfully installed revtok-0.0.3\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZOMJNW1qVgnD"},"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","\n","from torchtext.data import Field, BucketIterator, TabularDataset, ReversibleField\n","\n","import spacy\n","import numpy as np\n","\n","import random\n","import math\n","import time\n","\n","import pandas as pd\n","import string\n","import unidecode\n","\n","import revtok"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MTc4ZhCvc_3v","executionInfo":{"status":"ok","timestamp":1607261498352,"user_tz":-60,"elapsed":34511,"user":{"displayName":"Peter Chochula","photoUrl":"","userId":"03128571225950042155"}},"outputId":"9cf37fcd-edcc-4751-d9dd-f97e289c0d5b"},"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2AbayksSdfrP"},"source":["PATH_DATA = \"/content/drive/MyDrive/train.cs\"\n","file1 = open(PATH_DATA, 'r') \n","Lines = file1.readlines()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"o15tZrAzhnrw"},"source":["df = pd.DataFrame({'text':Lines})"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wlNXgqnviBqD"},"source":["df['text'] = df['text'].apply(lambda x: x.replace(\"\\n\", ''))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7RHqxSHNiWvh"},"source":["df['text'] = df['text'].apply(lambda x: x.split(' '))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LwMcQn28irFH"},"source":["df['text'] = df.explode('text').reset_index(drop=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"m-Lg6j9QjMNZ"},"source":["df['text'] = df['text'].apply(lambda x: x.translate(str.maketrans('', '', string.punctuation)))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lAeVDJpUj55J"},"source":["df['text'] = df['text'].apply(lambda x: x.lower())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7hDuGjW8kcUJ"},"source":["df['src_text'] = df['text'].apply(lambda x: unidecode.unidecode(x))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":419},"id":"LOmSim8U_vAv","executionInfo":{"status":"ok","timestamp":1607261499013,"user_tz":-60,"elapsed":35135,"user":{"displayName":"Peter Chochula","photoUrl":"","userId":"03128571225950042155"}},"outputId":"ea6d6cfc-0937-4e3e-f8de-bc1b93b13666"},"source":["df"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>src_text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>dva</td>\n","      <td>dva</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>mladí</td>\n","      <td>mladi</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>bílí</td>\n","      <td>bili</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>muži</td>\n","      <td>muzi</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>jsou</td>\n","      <td>jsou</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>28995</th>\n","      <td>na</td>\n","      <td>na</td>\n","    </tr>\n","    <tr>\n","      <th>28996</th>\n","      <td>vršku</td>\n","      <td>vrsku</td>\n","    </tr>\n","    <tr>\n","      <th>28997</th>\n","      <td>hory</td>\n","      <td>hory</td>\n","    </tr>\n","    <tr>\n","      <th>28998</th>\n","      <td>malý</td>\n","      <td>maly</td>\n","    </tr>\n","    <tr>\n","      <th>28999</th>\n","      <td>chlapec</td>\n","      <td>chlapec</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>29000 rows × 2 columns</p>\n","</div>"],"text/plain":["          text src_text\n","0          dva      dva\n","1        mladí    mladi\n","2         bílí     bili\n","3         muži     muzi\n","4         jsou     jsou\n","...        ...      ...\n","28995       na       na\n","28996    vršku    vrsku\n","28997     hory     hory\n","28998     malý     maly\n","28999  chlapec  chlapec\n","\n","[29000 rows x 2 columns]"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"PapEoTZDkxAF"},"source":["df.head(25000).to_csv(\"train.csv\", sep=',', index=False)\n","tmp = df.tail(4999)\n","tmp.head(3999).to_csv(\"test.csv\", sep=',', index=False)\n","tmp.tail(1000).to_csv(\"valid.csv\", sep=',', index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YE3QNR-eoIJJ"},"source":["def tokenize_words(text):\n","    tmp = list()\n","    tmp.append(text)\n","    return tmp"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BqIYd5yxlVIC"},"source":["SRC = ReversibleField(tokenize = tokenize_words, init_token=\"<sos>\", eos_token=\"<eos>\")\n","TRG = ReversibleField(tokenize = tokenize_words, init_token=\"<sos>\", eos_token=\"<eos>\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7zP-WBZSqrAj"},"source":["fields = {'src_text': (\"src\", SRC), \"text\": (\"trg\", TRG)}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mn9DryDfnBRq"},"source":["train_data, valid_data, test_data = TabularDataset.splits(\"/content/\", \n","                                                            train=\"train.csv\", \n","                                                            test=\"test.csv\", \n","                                                            validation=\"valid.csv\", \n","                                                            format='csv', \n","                                                            fields=fields)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SrQcCObtn-Om"},"source":["SRC.build_vocab(train_data, min_freq = 2)\n","TRG.build_vocab(train_data, min_freq = 2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sK0pLZYbEiKk","executionInfo":{"status":"ok","timestamp":1607261499477,"user_tz":-60,"elapsed":35570,"user":{"displayName":"Peter Chochula","photoUrl":"","userId":"03128571225950042155"}},"outputId":"1710e763-0630-4c6e-8300-0bf0cc6587b9"},"source":["print(vars(train_data.examples[0]))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["{'src': ['dva'], 'trg': ['dva']}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jyMT3RmArvyL"},"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9ohY6KW2r0Wj"},"source":["BATCH_SIZE = 128\n","\n","train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n","    (train_data, valid_data, test_data), \n","    batch_size = BATCH_SIZE, \n","    device = device,\n","    sort=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tc4S23yV1Lfj"},"source":["batch = next(iter(train_iterator))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8jrxrOyxsDDz"},"source":["class Encoder(nn.Module):\n","    def __init__(self, input_dim, emb_dim, hid_dim, n_layers, dropout):\n","        super().__init__()\n","        \n","        self.hid_dim = hid_dim\n","        self.n_layers = n_layers\n","        \n","        self.embedding = nn.Embedding(input_dim, emb_dim)\n","        \n","        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout = dropout)\n","        \n","        self.dropout = nn.Dropout(dropout)\n","        \n","    def forward(self, src):\n","        \n","        #src = [src len, batch size]\n","        \n","        embedded = self.dropout(self.embedding(src))\n","        \n","        #embedded = [src len, batch size, emb dim]\n","        \n","        outputs, (hidden, cell) = self.rnn(embedded)\n","        \n","        #outputs = [src len, batch size, hid dim * n directions]\n","        #hidden = [n layers * n directions, batch size, hid dim]\n","        #cell = [n layers * n directions, batch size, hid dim]\n","        \n","        #outputs are always from the top hidden layer\n","        \n","        return hidden, cell"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"R2YrpVRYsuYX"},"source":["class Decoder(nn.Module):\n","    def __init__(self, output_dim, emb_dim, hid_dim, n_layers, dropout):\n","        super().__init__()\n","        \n","        self.output_dim = output_dim\n","        self.hid_dim = hid_dim\n","        self.n_layers = n_layers\n","        \n","        self.embedding = nn.Embedding(output_dim, emb_dim)\n","        \n","        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout = dropout)\n","        \n","        self.fc_out = nn.Linear(hid_dim, output_dim)\n","        \n","        self.dropout = nn.Dropout(dropout)\n","        \n","    def forward(self, input, hidden, cell):\n","        \n","        #input = [batch size]\n","        #hidden = [n layers * n directions, batch size, hid dim]\n","        #cell = [n layers * n directions, batch size, hid dim]\n","        \n","        #n directions in the decoder will both always be 1, therefore:\n","        #hidden = [n layers, batch size, hid dim]\n","        #context = [n layers, batch size, hid dim]\n","        \n","        input = input.unsqueeze(0)\n","        \n","        #input = [1, batch size]\n","        \n","        embedded = self.dropout(self.embedding(input))\n","        \n","        #embedded = [1, batch size, emb dim]\n","                \n","        output, (hidden, cell) = self.rnn(embedded, (hidden, cell))\n","        \n","        #output = [seq len, batch size, hid dim * n directions]\n","        #hidden = [n layers * n directions, batch size, hid dim]\n","        #cell = [n layers * n directions, batch size, hid dim]\n","        \n","        #seq len and n directions will always be 1 in the decoder, therefore:\n","        #output = [1, batch size, hid dim]\n","        #hidden = [n layers, batch size, hid dim]\n","        #cell = [n layers, batch size, hid dim]\n","        \n","        prediction = self.fc_out(output.squeeze(0))\n","        \n","        #prediction = [batch size, output dim]\n","        \n","        return prediction, hidden, cell"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MdyOB0Xls4xC"},"source":["class Seq2Seq(nn.Module):\n","    def __init__(self, encoder, decoder, device):\n","        super().__init__()\n","        \n","        self.encoder = encoder\n","        self.decoder = decoder\n","        self.device = device\n","        \n","        assert encoder.hid_dim == decoder.hid_dim, \\\n","            \"Hidden dimensions of encoder and decoder must be equal!\"\n","        assert encoder.n_layers == decoder.n_layers, \\\n","            \"Encoder and decoder must have equal number of layers!\"\n","        \n","    def forward(self, src, trg, teacher_forcing_ratio = 0.5):\n","        \n","        #src = [src len, batch size]\n","        #trg = [trg len, batch size]\n","        #teacher_forcing_ratio is probability to use teacher forcing\n","        #e.g. if teacher_forcing_ratio is 0.75 we use ground-truth inputs 75% of the time\n","        \n","        batch_size = trg.shape[1]\n","        trg_len = trg.shape[0]\n","        trg_vocab_size = self.decoder.output_dim\n","        \n","        #tensor to store decoder outputs\n","        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n","        \n","        #last hidden state of the encoder is used as the initial hidden state of the decoder\n","        hidden, cell = self.encoder(src)\n","        \n","        #first input to the decoder is the <sos> tokens\n","        input = trg[0,:]\n","        \n","        for t in range(1, trg_len):\n","            \n","            #insert input token embedding, previous hidden and previous cell states\n","            #receive output tensor (predictions) and new hidden and cell states\n","            output, hidden, cell = self.decoder(input, hidden, cell)\n","            \n","            #place predictions in a tensor holding predictions for each token\n","            outputs[t] = output\n","            \n","            #decide if we are going to use teacher forcing or not\n","            teacher_force = random.random() < teacher_forcing_ratio\n","            \n","            #get the highest predicted token from our predictions\n","            top1 = output.argmax(1) \n","            \n","            #if teacher forcing, use actual next token as next input\n","            #if not, use predicted token\n","            input = trg[t] if teacher_force else top1\n","        \n","        return outputs"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3gn2QCGXs7yb"},"source":["INPUT_DIM = len(SRC.vocab)\n","OUTPUT_DIM = len(TRG.vocab)\n","ENC_EMB_DIM = 256\n","DEC_EMB_DIM = 256\n","HID_DIM = 512\n","N_LAYERS = 2\n","ENC_DROPOUT = 0.5\n","DEC_DROPOUT = 0.5\n","\n","enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n","dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)\n","\n","model = Seq2Seq(enc, dec, device).to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CclI24xHs_aP","executionInfo":{"status":"ok","timestamp":1607261517510,"user_tz":-60,"elapsed":53572,"user":{"displayName":"Peter Chochula","photoUrl":"","userId":"03128571225950042155"}},"outputId":"667e7efb-0403-4697-e1e3-eda111fdfbf7"},"source":["\n","def init_weights(m):\n","    for name, param in m.named_parameters():\n","        nn.init.normal_(param.data, mean=0, std=0.01)\n","        \n","model.apply(init_weights)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Seq2Seq(\n","  (encoder): Encoder(\n","    (embedding): Embedding(1926, 256)\n","    (rnn): LSTM(256, 512, num_layers=2, dropout=0.5)\n","    (dropout): Dropout(p=0.5, inplace=False)\n","  )\n","  (decoder): Decoder(\n","    (embedding): Embedding(1941, 256)\n","    (rnn): LSTM(256, 512, num_layers=2, dropout=0.5)\n","    (fc_out): Linear(in_features=512, out_features=1941, bias=True)\n","    (dropout): Dropout(p=0.5, inplace=False)\n","  )\n",")"]},"metadata":{"tags":[]},"execution_count":27}]},{"cell_type":"code","metadata":{"id":"5ik7YtP0zemY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607261517513,"user_tz":-60,"elapsed":53565,"user":{"displayName":"Peter Chochula","photoUrl":"","userId":"03128571225950042155"}},"outputId":"860ca1a8-d530-4a68-c70c-db6b0c07de3c"},"source":["\n","def count_parameters(model):\n","    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n","\n","print(f'The model has {count_parameters(model):,} trainable parameters')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["The model has 9,342,101 trainable parameters\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4UfKG6tBtIfL"},"source":["optimizer = optim.Adam(model.parameters())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"K72ekPPRtLbO"},"source":["criterion = nn.CrossEntropyLoss()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TnbUKffstOAS"},"source":["\n","def train(model, iterator, optimizer, criterion, clip):\n","    \n","    model.train()\n","    \n","    epoch_loss = 0\n","    \n","    for i, batch in enumerate(iterator):\n","        \n","        src = batch.src\n","        trg = batch.trg\n","        \n","        optimizer.zero_grad()\n","        \n","        output = model(src, trg)\n","        \n","        #trg = [trg len, batch size]\n","        #output = [trg len, batch size, output dim]\n","        \n","        output_dim = output.shape[-1]\n","        \n","        output = output[1:].view(-1, output_dim)\n","        trg = trg[1:].view(-1)\n","        \n","        #trg = [(trg len - 1) * batch size]\n","        #output = [(trg len - 1) * batch size, output dim]\n","        \n","        loss = criterion(output, trg)\n","        \n","        loss.backward()\n","        \n","        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n","        \n","        optimizer.step()\n","        \n","        epoch_loss += loss.item()\n","        \n","    return epoch_loss / len(iterator)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0VUc25pYtTTq"},"source":["def evaluate(model, iterator, criterion):\n","    \n","    model.eval()\n","    \n","    epoch_loss = 0\n","    \n","    with torch.no_grad():\n","    \n","        for i, batch in enumerate(iterator):\n","\n","            src = batch.src\n","            trg = batch.trg\n","\n","            output = model(src, trg, 0) #turn off teacher forcing\n","\n","            #trg = [trg len, batch size]\n","            #output = [trg len, batch size, output dim]\n","\n","            output_dim = output.shape[-1]\n","            \n","            output = output[1:].view(-1, output_dim)\n","            trg = trg[1:].view(-1)\n","\n","            #trg = [(trg len - 1) * batch size]\n","            #output = [(trg len - 1) * batch size, output dim]\n","\n","            loss = criterion(output, trg)\n","            \n","            epoch_loss += loss.item()\n","        \n","    return epoch_loss / len(iterator)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oAJBEq97tVJy"},"source":["def epoch_time(start_time, end_time):\n","    elapsed_time = end_time - start_time\n","    elapsed_mins = int(elapsed_time / 60)\n","    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n","    return elapsed_mins, elapsed_secs"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PkKev3cHtW6j","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607261622079,"user_tz":-60,"elapsed":158113,"user":{"displayName":"Peter Chochula","photoUrl":"","userId":"03128571225950042155"}},"outputId":"68498ea1-7bda-44b2-f434-00c604259cfc"},"source":["\n","N_EPOCHS = 20\n","CLIP = 1\n","\n","best_valid_loss = float('inf')\n","\n","for epoch in range(N_EPOCHS):\n","    \n","    start_time = time.time()\n","    \n","    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n","    valid_loss = evaluate(model, valid_iterator, criterion)\n","    \n","    end_time = time.time()\n","    \n","    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n","    \n","    if valid_loss < best_valid_loss:\n","        best_valid_loss = valid_loss\n","        torch.save(model.state_dict(), 'tut1-model.pt')\n","    \n","    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n","    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n","    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch: 01 | Time: 0m 5s\n","\tTrain Loss: 2.663 | Train PPL:  14.341\n","\t Val. Loss: 1.778 |  Val. PPL:   5.917\n","Epoch: 02 | Time: 0m 5s\n","\tTrain Loss: 1.905 | Train PPL:   6.717\n","\t Val. Loss: 1.609 |  Val. PPL:   4.998\n","Epoch: 03 | Time: 0m 5s\n","\tTrain Loss: 1.799 | Train PPL:   6.044\n","\t Val. Loss: 1.491 |  Val. PPL:   4.443\n","Epoch: 04 | Time: 0m 5s\n","\tTrain Loss: 1.723 | Train PPL:   5.604\n","\t Val. Loss: 1.432 |  Val. PPL:   4.187\n","Epoch: 05 | Time: 0m 5s\n","\tTrain Loss: 1.680 | Train PPL:   5.368\n","\t Val. Loss: 1.407 |  Val. PPL:   4.082\n","Epoch: 06 | Time: 0m 5s\n","\tTrain Loss: 1.647 | Train PPL:   5.194\n","\t Val. Loss: 1.370 |  Val. PPL:   3.934\n","Epoch: 07 | Time: 0m 5s\n","\tTrain Loss: 1.621 | Train PPL:   5.059\n","\t Val. Loss: 1.335 |  Val. PPL:   3.801\n","Epoch: 08 | Time: 0m 5s\n","\tTrain Loss: 1.597 | Train PPL:   4.936\n","\t Val. Loss: 1.328 |  Val. PPL:   3.772\n","Epoch: 09 | Time: 0m 5s\n","\tTrain Loss: 1.582 | Train PPL:   4.866\n","\t Val. Loss: 1.298 |  Val. PPL:   3.661\n","Epoch: 10 | Time: 0m 5s\n","\tTrain Loss: 1.560 | Train PPL:   4.761\n","\t Val. Loss: 1.283 |  Val. PPL:   3.608\n","Epoch: 11 | Time: 0m 5s\n","\tTrain Loss: 1.541 | Train PPL:   4.669\n","\t Val. Loss: 1.282 |  Val. PPL:   3.603\n","Epoch: 12 | Time: 0m 5s\n","\tTrain Loss: 1.521 | Train PPL:   4.577\n","\t Val. Loss: 1.249 |  Val. PPL:   3.487\n","Epoch: 13 | Time: 0m 5s\n","\tTrain Loss: 1.501 | Train PPL:   4.488\n","\t Val. Loss: 1.240 |  Val. PPL:   3.456\n","Epoch: 14 | Time: 0m 5s\n","\tTrain Loss: 1.467 | Train PPL:   4.338\n","\t Val. Loss: 1.197 |  Val. PPL:   3.311\n","Epoch: 15 | Time: 0m 5s\n","\tTrain Loss: 1.403 | Train PPL:   4.066\n","\t Val. Loss: 1.127 |  Val. PPL:   3.087\n","Epoch: 16 | Time: 0m 5s\n","\tTrain Loss: 1.320 | Train PPL:   3.744\n","\t Val. Loss: 1.047 |  Val. PPL:   2.850\n","Epoch: 17 | Time: 0m 5s\n","\tTrain Loss: 1.220 | Train PPL:   3.388\n","\t Val. Loss: 0.932 |  Val. PPL:   2.540\n","Epoch: 18 | Time: 0m 5s\n","\tTrain Loss: 1.118 | Train PPL:   3.059\n","\t Val. Loss: 0.849 |  Val. PPL:   2.337\n","Epoch: 19 | Time: 0m 5s\n","\tTrain Loss: 1.020 | Train PPL:   2.773\n","\t Val. Loss: 0.743 |  Val. PPL:   2.102\n","Epoch: 20 | Time: 0m 5s\n","\tTrain Loss: 0.927 | Train PPL:   2.526\n","\t Val. Loss: 0.665 |  Val. PPL:   1.944\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"sG5pZgDu5xSn"},"source":["def translate_sentence(model, sentence, src, trg, device, max_length=50):\n","\n","    # Create tokens \n","    if type(sentence) == str:\n","        tmp = list()\n","        tmp.append(sentence)\n","        tokens = tmp\n","    # else:\n","    #     tokens = [token.lower() for token in sentence]\n","\n","    # print(tokens)\n","\n","    # sys.exit()\n","    # Add <SOS> and <EOS> in beginning and end respectively\n","    tokens.insert(0, SRC.init_token)\n","    tokens.append(SRC.eos_token)\n","\n","    # Go through each src token and convert to an index\n","    text_to_indices = [SRC.vocab.stoi[token] for token in tokens]\n","\n","    # Convert to Tensor\n","    sentence_tensor = torch.LongTensor(text_to_indices).unsqueeze(1).to(device)\n","\n","    # Build encoder hidden, cell state\n","    with torch.no_grad():\n","        hidden, cell = model.encoder(sentence_tensor)\n","\n","    outputs = [TRG.vocab.stoi[\"<sos>\"]]\n","\n","    for _ in range(max_length):\n","        previous_word = torch.LongTensor([outputs[-1]]).to(device)\n","\n","        with torch.no_grad():\n","            output, hidden, cell = model.decoder(previous_word, hidden, cell)\n","            best_guess = output.argmax(1).item()\n","\n","        outputs.append(best_guess)\n","\n","        # Model predicts it's the end of the sentence\n","        if output.argmax(1).item() == TRG.vocab.stoi[\"<eos>\"]:\n","            break\n","\n","    translated_sentence = [TRG.vocab.itos[idx] for idx in outputs]\n","\n","    # remove start token\n","    return translated_sentence[1:]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Eqx_5w9o-_Mh","executionInfo":{"status":"ok","timestamp":1607261716095,"user_tz":-60,"elapsed":1017,"user":{"displayName":"Peter Chochula","photoUrl":"","userId":"03128571225950042155"}},"outputId":"b0169156-c60b-4efe-d87e-7e91fde4abed"},"source":["translate_sentence(model, \"maly\", SRC, TRG, device, 1)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['malý']"]},"metadata":{"tags":[]},"execution_count":45}]},{"cell_type":"code","metadata":{"id":"L05p1tFm-jJJ"},"source":[""],"execution_count":null,"outputs":[]}]}