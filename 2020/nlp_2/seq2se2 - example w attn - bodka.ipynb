{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"vui2 - seq2seq w attention.ipynb","provenance":[{"file_id":"1XqkJAEu1oy80rwS-mGePAl5cgE8zEqxS","timestamp":1607266186662}],"authorship_tag":"ABX9TyOKijYDsTyCu1nHJsEWuYoN"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"wwNElIVF-NuJ"},"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torchtext.data import Field, BucketIterator\n","import torch.nn.functional as F\n","import nltk\n","import numpy as np\n","import spacy \n","import random\n","import string\n","from torch.utils.tensorboard import SummaryWriter #to print to tensorboard\n","import pandas as pd\n","import unicodedata\n","import re"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TUUgOWX0-dON"},"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GtqCoFAu_MSC","executionInfo":{"status":"ok","timestamp":1606648476214,"user_tz":-60,"elapsed":471,"user":{"displayName":"Peter Chochula","photoUrl":"","userId":"03128571225950042155"}},"outputId":"ba8165e9-4bb8-4078-a08d-4657f89c69a7"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive/')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w47hgdDH_QAp","executionInfo":{"status":"ok","timestamp":1606648479659,"user_tz":-60,"elapsed":3588,"user":{"displayName":"Peter Chochula","photoUrl":"","userId":"03128571225950042155"}},"outputId":"90113cdd-2149-47b6-85e5-0aea57acc2bd"},"source":["!python -m spacy download en"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n","Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n","Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.4)\n","Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n","Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.4)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.41.1)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.4)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n","Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.8.0)\n","Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (50.3.2)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.18.5)\n","Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n","Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.11.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.4.0)\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the model via spacy.load('en_core_web_sm')\n","\u001b[38;5;2m✔ Linking successful\u001b[0m\n","/usr/local/lib/python3.6/dist-packages/en_core_web_sm -->\n","/usr/local/lib/python3.6/dist-packages/spacy/data/en\n","You can now load the model via spacy.load('en')\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7FmYOItuCs9d"},"source":["spacy_eng = spacy.load('en')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qQoeh3sDCgsC"},"source":["def tokenizer_eng(text):\n","    return [tok.text for tok in spacy_eng.tokenizer(text)]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oXHdMyrlC_WL"},"source":["def sentencizer_eng(text):\n","    return [sent + ' .' for sent in text.split('.') if len(sent.split(' ')) < 20 and len(sent.split(' ')) > 2]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cTw5aLmpE-0i"},"source":["def clear_punctuation(text):\n","    t = text.translate(str.maketrans('', '', string.punctuation))\n","    t = re.sub(' +', ' ', t)\n","    return t"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"35y1q-VBJKN3"},"source":["def unicodeToAscii(s):\n","    return ''.join(\n","        c for c in unicodedata.normalize('NFD', s)\n","        if unicodedata.category(c) != 'Mn'\n","    )\n","\n","\n","def normalizeString(s):\n","    s = unicodeToAscii(s.lower().strip())\n","    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n","    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n","    return s"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"H3LCyoK6pV5Q"},"source":["PATH_DATA = \"/content/gdrive/MyDrive/articles.csv\"\n","df = pd.read_csv(PATH_DATA)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":419},"id":"GmzLai5VpXy-","executionInfo":{"status":"ok","timestamp":1606648491214,"user_tz":-60,"elapsed":571,"user":{"displayName":"Peter Chochula","photoUrl":"","userId":"03128571225950042155"}},"outputId":"b4422271-8f1d-4efb-c052-2133c0aebfd0"},"source":["df"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>article_text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>General Motors (NYSE: GM ): Q4 Non-GAAP EPS of...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Azure Power (NYSE: AZRE ) : FQ1 EPS of $0.01 m...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Morgan Stanley slots in General Motors ( GM  +...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Cruise (NYSE: GM ) CEO Dan Ammann sees the glo...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>II-VI Incorporated (NASDAQ: IIVI ) Q4 2020 Ear...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>9935</th>\n","      <td>The following slide deck was published by Twis...</td>\n","    </tr>\n","    <tr>\n","      <th>9936</th>\n","      <td>I've been doing some due diligence on REITs I ...</td>\n","    </tr>\n","    <tr>\n","      <th>9937</th>\n","      <td>As a buy and hold investor, it is anathema to ...</td>\n","    </tr>\n","    <tr>\n","      <th>9938</th>\n","      <td>J.P. Morgan analyst Steve Tusa cuts General El...</td>\n","    </tr>\n","    <tr>\n","      <th>9939</th>\n","      <td>General Electric (NYSE: GE ) closed -2.2% , re...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>9940 rows × 1 columns</p>\n","</div>"],"text/plain":["                                           article_text\n","0     General Motors (NYSE: GM ): Q4 Non-GAAP EPS of...\n","1     Azure Power (NYSE: AZRE ) : FQ1 EPS of $0.01 m...\n","2     Morgan Stanley slots in General Motors ( GM  +...\n","3     Cruise (NYSE: GM ) CEO Dan Ammann sees the glo...\n","4     II-VI Incorporated (NASDAQ: IIVI ) Q4 2020 Ear...\n","...                                                 ...\n","9935  The following slide deck was published by Twis...\n","9936  I've been doing some due diligence on REITs I ...\n","9937  As a buy and hold investor, it is anathema to ...\n","9938  J.P. Morgan analyst Steve Tusa cuts General El...\n","9939  General Electric (NYSE: GE ) closed -2.2% , re...\n","\n","[9940 rows x 1 columns]"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"XR_wGIDT_iE_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606648505262,"user_tz":-60,"elapsed":4581,"user":{"displayName":"Peter Chochula","photoUrl":"","userId":"03128571225950042155"}},"outputId":"07cade8d-d5aa-4365-daa5-430ca009c517"},"source":["mask = df['article_text'].str.len() >= 1000\n","df = df.loc[mask]\n","df.reset_index(drop=True, inplace=True)\n","df['article_text'] = df['article_text'].apply(lambda x: sentencizer_eng(x))\n","df = df.explode('article_text').reset_index(drop=True).dropna()\n","df = df.groupby(df.index // 2).agg(' '.join)\n","df['article_text'] = df['article_text'].apply(lambda x: x[:-2])\n","df[\"article_text_no_punct\"] = df['article_text'].apply(lambda x: clear_punctuation(x))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  after removing the cwd from sys.path.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"Ggjv9n1KBtUT","executionInfo":{"status":"ok","timestamp":1606648521894,"user_tz":-60,"elapsed":406,"user":{"displayName":"Peter Chochula","photoUrl":"","userId":"03128571225950042155"}},"outputId":"f990ca17-1861-4b72-a6d0-ab12dbeb7f5d"},"source":["df.iloc[5]['article_text_no_punct']"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["' Welcome to our earnings call today for the fourth quarter and the year end for fiscal year 2020 With me today on the call are Dr'"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"Fr21cryeCj00","executionInfo":{"status":"ok","timestamp":1606648525871,"user_tz":-60,"elapsed":438,"user":{"displayName":"Peter Chochula","photoUrl":"","userId":"03128571225950042155"}},"outputId":"d87a3ea7-893d-4ce1-8605-3b19f0def1e0"},"source":["df.iloc[5]['article_text']"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["' Welcome to our earnings call today for the fourth quarter and the year end for fiscal year 2020 .  With me today on the call are Dr'"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"PZPX8_W6JsxV"},"source":["df['article_text'] = df['article_text'].apply(lambda x: normalizeString(x))\n","df['article_text_no_punct'] = df['article_text_no_punct'].apply(lambda x: normalizeString(x))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"27-Z3N1eF7lM","executionInfo":{"status":"ok","timestamp":1606648564839,"user_tz":-60,"elapsed":478,"user":{"displayName":"Peter Chochula","photoUrl":"","userId":"03128571225950042155"}},"outputId":"fe38d748-579a-453a-d7e8-809f7065f919"},"source":["df.iloc[5]['article_text']"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'welcome to our earnings call today for the fourth quarter and the year end for fiscal year . with me today on the call are dr'"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"FhI8YgaxBfzk"},"source":["SOS_token = 0\n","EOS_token = 1\n","\n","class Lang:\n","    def __init__(self, name):\n","        self.name = name\n","        self.word2index = {}\n","        self.word2count = {}\n","        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n","        self.n_words = 2  # Count SOS and EOS\n","\n","    def addSentences(self, sentence):\n","        for word in sentence.split(' '):\n","            self.addWord(word)\n","\n","    def addWord(self, word):\n","        if word not in self.word2index:\n","            self.word2index[word] = self.n_words\n","            self.word2count[word] = 1\n","            self.index2word[self.n_words] = word\n","            self.n_words += 1\n","        else:\n","            self.word2count[word] += 1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WnHHo3gzJZk3"},"source":["punctuation_lang = Lang('punc')\n","without_punctuation_lang = Lang('without_punc')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RYUVUG-wKXLC"},"source":["def fill_language(lang, df, column):\n","    [lang.addSentences(x) for x in df[column]]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"a_SLG18yLYpB"},"source":["fill_language(punctuation_lang, df, 'article_text')\n","fill_language(without_punctuation_lang, df, 'article_text_no_punct')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"09fbIX-tMO8O"},"source":["class EncoderRNN(nn.Module):\n","    def __init__(self, input_size, hidden_size):\n","        super(EncoderRNN, self).__init__()\n","        self.hidden_size = hidden_size\n","\n","        self.embedding = nn.Embedding(input_size, hidden_size)\n","        self.gru = nn.GRU(hidden_size, hidden_size)\n","\n","    def forward(self, input, hidden):\n","        embedded = self.embedding(input).view(1, 1, -1)\n","        output = embedded\n","        output, hidden = self.gru(output, hidden)\n","        return output, hidden\n","\n","    def initHidden(self):\n","        return torch.zeros(1, 1, self.hidden_size, device=device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"U9nljb6QMxxs"},"source":["class AttnDecoderRNN(nn.Module):\n","\n","    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=40):\n","        super(AttnDecoderRNN, self).__init__()\n","        self.hidden_size = hidden_size\n","        self.output_size = output_size\n","        self.dropout_p = dropout_p\n","        self.max_length = max_length\n","\n","        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n","        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n","        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n","        self.dropout = nn.Dropout(self.dropout_p)\n","        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n","        self.out = nn.Linear(self.hidden_size, self.output_size)\n","\n","    def forward(self, input, hidden, encoder_outputs):\n","        embedded = self.embedding(input).view(1, 1, -1)\n","        embedded = self.dropout(embedded)\n","\n","        attn_weights = F.softmax(\n","            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n","        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n","                                 encoder_outputs.unsqueeze(0))\n","\n","        output = torch.cat((embedded[0], attn_applied[0]), 1)\n","        output = self.attn_combine(output).unsqueeze(0)\n","\n","        output = F.relu(output)\n","        output, hidden = self.gru(output, hidden)\n","\n","        output = F.log_softmax(self.out(output[0]), dim=1)\n","        return output, hidden, attn_weights\n","\n","    def initHidden(self):\n","        return torch.zeros(1, 1, self.hidden_size, device=device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"M1z1nJAoM77D"},"source":["def indexesFromSentence(lang, sentence):\n","    return [lang.word2index[word] for word in sentence.split(' ')]\n","\n","\n","def tensorFromSentence(lang, sentence):\n","    indexes = indexesFromSentence(lang, sentence)\n","    indexes.append(EOS_token)\n","    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n","\n","\n","def tensorsFromPair(pair):\n","    input_tensor = tensorFromSentence(without_punctuation_lang, pair[0])\n","    target_tensor = tensorFromSentence(punctuation_lang, pair[1])\n","    return (input_tensor, target_tensor)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ddldyDjHHfk8"},"source":["def create_random_pair():\n","    row = random.randint(0, len(df)-1)\n","    return [df.iloc[row]['article_text_no_punct'], df.iloc[row]['article_text']]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6UPG9wtDNpZ2"},"source":["teacher_forcing_ratio = 0.5\n","MAX_LENGTH = 40\n","\n","def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n","    encoder_hidden = encoder.initHidden()\n","\n","    encoder_optimizer.zero_grad()\n","    decoder_optimizer.zero_grad()\n","\n","    input_length = input_tensor.size(0)\n","    target_length = target_tensor.size(0)\n","\n","    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n","\n","    loss = 0\n","\n","    for ei in range(input_length):\n","        encoder_output, encoder_hidden = encoder(\n","            input_tensor[ei], encoder_hidden)\n","        encoder_outputs[ei] = encoder_output[0, 0]\n","\n","    decoder_input = torch.tensor([[SOS_token]], device=device)\n","\n","    decoder_hidden = encoder_hidden\n","\n","    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n","\n","    if use_teacher_forcing:\n","        # Teacher forcing: Feed the target as the next input\n","        for di in range(target_length):\n","            decoder_output, decoder_hidden, decoder_attention = decoder(\n","                decoder_input, decoder_hidden, encoder_outputs)\n","            loss += criterion(decoder_output, target_tensor[di])\n","            decoder_input = target_tensor[di]  # Teacher forcing\n","\n","    else:\n","        # Without teacher forcing: use its own predictions as the next input\n","        for di in range(target_length):\n","            decoder_output, decoder_hidden, decoder_attention = decoder(\n","                decoder_input, decoder_hidden, encoder_outputs)\n","            topv, topi = decoder_output.topk(1)\n","            decoder_input = topi.squeeze().detach()  # detach from history as input\n","\n","            loss += criterion(decoder_output, target_tensor[di])\n","            if decoder_input.item() == EOS_token:\n","                break\n","\n","    loss.backward()\n","\n","    encoder_optimizer.step()\n","    decoder_optimizer.step()\n","\n","    return loss.item() / target_length"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AKxHQg77N9qm"},"source":["import time\n","import math\n","\n","def asMinutes(s):\n","    m = math.floor(s / 60)\n","    s -= m * 60\n","    return '%dm %ds' % (m, s)\n","\n","def timeSince(since, percent):\n","    now = time.time()\n","    s = now - since\n","    es = s / (percent)\n","    rs = es - s\n","    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jMJR2tc2Oq4B"},"source":["def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n","    start = time.time()\n","    plot_losses = []\n","    print_loss_total = 0  # Reset every print_every\n","    plot_loss_total = 0  # Reset every plot_every\n","\n","    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n","    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n","    training_pairs = [tensorsFromPair(create_random_pair())\n","                      for i in range(n_iters)]\n","    criterion = nn.NLLLoss()\n","\n","    for iter in range(1, n_iters + 1):\n","        training_pair = training_pairs[iter - 1]\n","        input_tensor = training_pair[0]\n","        target_tensor = training_pair[1]\n","\n","        loss = train(input_tensor, target_tensor, encoder,\n","                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n","        print_loss_total += loss\n","        plot_loss_total += loss\n","\n","        if iter % print_every == 0:\n","            print_loss_avg = print_loss_total / print_every\n","            print_loss_total = 0\n","            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n","                                         iter, iter / n_iters * 100, print_loss_avg))\n","\n","        if iter % plot_every == 0:\n","            plot_loss_avg = plot_loss_total / plot_every\n","            plot_losses.append(plot_loss_avg)\n","            plot_loss_total = 0\n","\n","    showPlot(plot_losses)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ol40M25IOunC"},"source":["import matplotlib.pyplot as plt\n","plt.switch_backend('agg')\n","import matplotlib.ticker as ticker\n","import numpy as np\n","\n","\n","def showPlot(points):\n","    plt.figure()\n","    fig, ax = plt.subplots()\n","    # this locator puts ticks at regular intervals\n","    loc = ticker.MultipleLocator(base=0.2)\n","    ax.yaxis.set_major_locator(loc)\n","    plt.plot(points)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WTet-RdLOyv5"},"source":["hidden_size = 256\n","encoder1 = EncoderRNN(without_punctuation_lang.n_words, hidden_size).to(device)\n","attn_decoder1 = AttnDecoderRNN(hidden_size, punctuation_lang.n_words, dropout_p=0.1).to(device)\n","\n","trainIters(encoder1, attn_decoder1, 175000, print_every=5000)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BLY-IRhxO6dg"},"source":["def evaluate(encoder, decoder, sentence, max_length=40):\n","    with torch.no_grad():\n","        input_tensor = tensorFromSentence(without_punctuation_lang, sentence)\n","        input_length = input_tensor.size()[0]\n","        encoder_hidden = encoder.initHidden()\n","\n","        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n","\n","        for ei in range(input_length):\n","            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n","                                                     encoder_hidden)\n","            encoder_outputs[ei] += encoder_output[0, 0]\n","\n","        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n","\n","        decoder_hidden = encoder_hidden\n","\n","        decoded_words = []\n","        decoder_attentions = torch.zeros(max_length, max_length)\n","\n","        for di in range(max_length):\n","            decoder_output, decoder_hidden, decoder_attention = decoder(\n","                decoder_input, decoder_hidden, encoder_outputs)\n","            decoder_attentions[di] = decoder_attention.data\n","            topv, topi = decoder_output.data.topk(1)\n","            if topi.item() == EOS_token:\n","                decoded_words.append('<EOS>')\n","                break\n","            else:\n","                decoded_words.append(punctuation_lang.index2word[topi.item()])\n","\n","            decoder_input = topi.squeeze().detach()\n","\n","        return decoded_words, decoder_attentions[:di + 1]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5zrJ-NA_qcfN"},"source":["def evaluateRandomly(encoder, decoder, n=10):\n","    for i in range(n):\n","        pair = create_random_pair()\n","        print('>', pair[0])\n","        print('=', pair[1])\n","        output_words, attentions = evaluate(encoder, decoder, pair[0])\n","        output_sentence = ' '.join(output_words)\n","        print('----->', output_sentence)\n","        print('')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xAyeG1qiuAVj"},"source":["evaluateRandomly(encoder1, attn_decoder1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cFS3BgqfvjN5"},"source":[""],"execution_count":null,"outputs":[]}]}